{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.NER_with_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5N47oS8WM6OY",
        "zYWIys6BM6Ob",
        "WbY3ZstAM6OV",
        "WwAHj6mPM6Od",
        "YKp_pARIM6Oe"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GsDDSmTM6N9"
      },
      "source": [
        "# NER with BERT in Spark NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TZw9vE5M6OH"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRhmsIcCM6OH",
        "outputId": "0282778e-a06e-4a64-d66f-18fca7984be5"
      },
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-29 11:39:35--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-11-29 11:39:37--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-11-29 11:39:38--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-29 11:39:39 (44.1 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylCinY-tM6OI"
      },
      "source": [
        "## Import libraries and download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6rnibyVM6OI"
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9mD4BObM6OI",
        "outputId": "b59cc47d-e233-4db6-fe9f-8e412f3af935"
      },
      "source": [
        "# if you have GPU\n",
        "spark = sparknlp.start(gpu=True)\n",
        "#spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.3.4\n",
            "Apache Spark version:  3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnfsIM1MM6OJ",
        "outputId": "a7125db8-0ddb-4e23-875b-2130fb1f5b8c"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "urlretrieve('https://github.com/JohnSnowLabs/spark-nlp/raw/master/src/test/resources/conll2003/eng.train',\n",
        "           'eng.train')\n",
        "\n",
        "urlretrieve('https://github.com/JohnSnowLabs/spark-nlp/raw/master/src/test/resources/conll2003/eng.testa',\n",
        "           'eng.testa')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('eng.testa', <http.client.HTTPMessage at 0x7f8ec72bab90>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksp7t3WKM6OK",
        "outputId": "028c163f-83ad-4591-c0b4-d4db531e6e11"
      },
      "source": [
        "with open(\"eng.train\") as f:\n",
        "    c=f.read()\n",
        "\n",
        "print (c[:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP B-NP B-PER\n",
            "Black\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNhRXZ1M6OK"
      },
      "source": [
        "## Building NER pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOgifXmgM6OL",
        "outputId": "70d0724b-f879-4cfe-83e9-9100baf672e0"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6R1bF9QM6OL",
        "outputId": "5175d87c-a732-4595-9bf4-b6e67f2a7dfb"
      },
      "source": [
        "training_data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14041"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPHBKA1FM6OL"
      },
      "source": [
        "### Loading Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4IA9Rn0M6OL"
      },
      "source": [
        "In Spark NLP, we have four pre-trained variants of BERT: bert_base_uncased , bert_base_cased , bert_large_uncased , bert_large_cased, and many Smaller BERT models available on our [Models Hub](https://nlp.johnsnowlabs.com/models?q=bert&task=Embeddings). Which one to use depends on your use case, train set, and the complexity of the task you are trying to model.\n",
        "\n",
        "In the code snippet above, we basically load the bert_base_cased version from Spark NLP public resources and point the sentence and token columns in   setInputCols(). In short, BertEmbeddings() annotator will take sentence and token columns and populate Bert embeddings in bert column. In general, each word is translated to a 768-dimensional vector.\n",
        "\n",
        "As explained by the authors of official BERT paper, different BERT layers capture different information. The last layer is too closed to the target functions (i.e. masked language model and next sentence prediction) during pre-training, therefore it may be biased to those targets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-HV69OEM6OM",
        "outputId": "7a091c80-d316-470a-a7bc-af9be31fdade"
      },
      "source": [
        "# we use BERT Tiny\n",
        "bert_annotator = BertEmbeddings.pretrained('small_bert_L2_128', 'en') \\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        ".setBatchSize(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "small_bert_L2_128 download started this may take some time.\n",
            "Approximate size to download 16.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVs0qpz7M6OM",
        "outputId": "77eb147f-6b56-46a9-d37d-e6d70210aa22"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "\n",
        "test_data = bert_annotator.transform(test_data)\n",
        "\n",
        "test_data.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|                bert|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM-nQblLPkPf"
      },
      "source": [
        "# let's transform and save our test dataset for evaluation\n",
        "#test_data.write.parquet(\"test_withEmbeds.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vufW7YRM6ON",
        "outputId": "e8e26324-0902-4c26-99eb-9c0f1b5f48e7"
      },
      "source": [
        "test_data.select(\"bert.result\",\"bert.embeddings\",'label.result').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|              result|          embeddings|              result|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|[cricket, -, leic...|[[-1.6099557, 0.5...|[O, O, B-ORG, O, ...|\n",
            "|[london, 1996-08-30]|[[-0.660743, 0.72...|          [B-LOC, O]|\n",
            "|[west, indian, al...|[[-1.2108899, 0.9...|[B-MISC, I-MISC, ...|\n",
            "|[their, stay, on,...|[[-0.93976355, 0....|[O, O, O, O, O, O...|\n",
            "|[after, bowling, ...|[[-1.1267807, 1.1...|[O, O, B-ORG, O, ...|\n",
            "|[trailing, by, 21...|[[-1.8359263, 0.4...|[O, O, O, O, B-OR...|\n",
            "|[essex, ,, howeve...|[[-1.2150189, 0.2...|[B-ORG, O, O, O, ...|\n",
            "|[hussain, ,, cons...|[[-1.6078962, 0.5...|[B-PER, O, O, O, ...|\n",
            "|[by, the, close, ...|[[-1.8683758, 1.1...|[O, O, O, B-ORG, ...|\n",
            "|[at, the, oval, ,...|[[-1.874095, 0.69...|[O, O, B-LOC, O, ...|\n",
            "|[he, was, well, b...|[[-1.6607127, 1.2...|[O, O, O, O, O, B...|\n",
            "|[derbyshire, kept...|[[-1.1823791, 0.2...|[B-ORG, O, O, O, ...|\n",
            "|[australian, tom,...|[[-1.1873065, 2.1...|[B-MISC, B-PER, I...|\n",
            "|[after, the, frus...|[[-1.8415078, 1.3...|[O, O, O, O, O, O...|\n",
            "|[they, were, held...|[[-1.2608179, 0.8...|[O, O, O, O, O, O...|\n",
            "|[by, stumps, kent...|[[-1.6587896, 1.5...|[O, O, B-ORG, O, ...|\n",
            "|[cricket, -, engl...|[[-1.5593706, 0.2...|[O, O, B-MISC, I-...|\n",
            "|[london, 1996-08-30]|[[-0.660743, 0.72...|          [B-LOC, O]|\n",
            "|[result, and, clo...|[[-2.2526515, 0.2...|[O, O, O, O, O, O...|\n",
            "|[leicester, :, le...|[[-0.96010137, 0....|[B-LOC, O, B-ORG,...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJyP74zgM6OQ"
      },
      "source": [
        "nerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(5)\\\n",
        "  .setLr(0.001)\\\n",
        "  .setPo(0.005)\\\n",
        "  .setBatchSize(32)\\\n",
        "  .setEvaluationLogExtended(True) \\\n",
        "  .setEnableOutputLogs(True)\\\n",
        "  .setTestDataset(\"test_withEmbeds.parquet\")\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    bert_annotator,\n",
        "    nerTagger\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYJT6mHLM6OQ"
      },
      "source": [
        "You can also set learning rate ( setLr ), learning rate decay coefficient ( setPo ), setBatchSize and setDropout rate. Please see the [official APIs](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.html) for the entire list. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2wCMb1XmM6OR",
        "outputId": "56df6773-6e0b-448f-e413-5190ee034b85"
      },
      "source": [
        "%%time\n",
        "\n",
        "ner_model = pipeline.fit(training_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6.53 s, sys: 627 ms, total: 7.16 s\n",
            "Wall time: 22min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtLbO6RfP-y7",
        "outputId": "096d70d9-0df3-412f-f978-2743358c5bc2"
      },
      "source": [
        "!ls -l /root/annotator_logs/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "-rw-r--r-- 1 root root 4207 Nov 29 11:37 NerDLApproach_65a399dd5a1f.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zAvs21PQDU1",
        "outputId": "09f507dd-77c0-4042-92b6-d2a049cf9cd2"
      },
      "source": [
        "!cat /root/annotator_logs/NerDLApproach_16a0e7b3577f.log"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /root/annotator_logs/NerDLApproach_16a0e7b3577f.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo-GNidLr1wt"
      },
      "source": [
        "**Some notes:**\n",
        "- we used the smallest BERT model called BERT Tiny\n",
        "- it's very small and requires less memory among Transformers\n",
        "- if you have more memory or access to accelerated hardware please choose a larger BERT model for higher accuracy\n",
        "- you can also set higher Epoch to reach our STOA metrics\n",
        "\n",
        "We chose the smallest BERT model with only 5 Epochs for the sake of this tutorial within this small Colab VM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApUISh0AM6OR"
      },
      "source": [
        "# let's save our trained NER model on disk\n",
        "# so we can load it in a new session or move it to another location\n",
        "# since we fit NerDL model inside the pipeline, we can access it via stages\n",
        "ner_model.stages[1].write().overwrite().save('./NER_bert_20200219')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WehIZ-d9s5Ok",
        "outputId": "d697ee66-fc88-4c95-f58b-2c1ead4e834a"
      },
      "source": [
        "test_data.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|                bert|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Their stay on top...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 4, Th...|[[pos, 0, 4, PRP$...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|After bowling Som...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Trailing by 213 ,...|[[document, 0, 12...|[[document, 0, 12...|[[token, 0, 7, Tr...|[[pos, 0, 7, VBG,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Essex , however ,...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Es...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Hussain , conside...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 6, Hu...|[[pos, 0, 6, NN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|By the close York...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|At the Oval , Sur...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 1, At...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|He was well backe...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Derbyshire kept u...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 9, De...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Australian Tom Mo...|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 9, Au...|[[pos, 0, 9, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|After the frustra...|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|They were held up...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 3, Th...|[[pos, 0, 3, PRP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|By stumps Kent ha...|[[document, 0, 41...|[[document, 0, 41...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|CRICKET - ENGLISH...|[[document, 0, 45...|[[document, 0, 45...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Result and close ...|[[document, 0, 81...|[[document, 0, 81...|[[token, 0, 5, Re...|[[pos, 0, 5, NN, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|Leicester : Leice...|[[document, 0, 67...|[[document, 0, 67...|[[token, 0, 8, Le...|[[pos, 0, 8, JJ, ...|[[named_entity, 0...|[[word_embeddings...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiQvE5pmM6OS",
        "outputId": "a9e54ff2-6eaf-42f3-d7fc-c8ad0b180da3"
      },
      "source": [
        "# let's only feed sentence and token from our test dataset\n",
        "predictions = ner_model.transform(test_data.select(\"sentence\", \"token\", \"label\"))\n",
        "predictions.show(3)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|            sentence|               token|               label|                bert|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|[[document, 0, 64...|[[token, 0, 6, CR...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|[[document, 0, 16...|[[token, 0, 5, LO...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|[[document, 0, 18...|[[token, 0, 3, We...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eTDVoCxM6OS",
        "outputId": "fc3d61cc-d546-4cdb-c313-c1b26b27611e"
      },
      "source": [
        "predictions.select('token.result','label.result','ner.result').show(truncate=40)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                                  result|                                  result|                                  result|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|[CRICKET, -, LEICESTERSHIRE, TAKE, OV...|   [O, O, B-ORG, O, O, O, O, O, O, O, O]|   [O, O, B-ORG, O, O, O, O, O, O, O, O]|\n",
            "|                    [LONDON, 1996-08-30]|                              [B-LOC, O]|                              [B-LOC, O]|\n",
            "|[West, Indian, all-rounder, Phil, Sim...|[B-MISC, I-MISC, O, B-PER, I-PER, O, ...|[B-MISC, I-MISC, O, B-PER, I-PER, O, ...|\n",
            "|[Their, stay, on, top, ,, though, ,, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[After, bowling, Somerset, out, for, ...|[O, O, B-ORG, O, O, O, O, O, O, O, O,...|[O, O, B-ORG, O, O, O, O, O, O, O, O,...|\n",
            "|[Trailing, by, 213, ,, Somerset, got,...|[O, O, O, O, B-ORG, O, O, O, O, O, O,...|[O, O, O, O, B-PER, O, O, O, O, O, O,...|\n",
            "|[Essex, ,, however, ,, look, certain,...|[B-ORG, O, O, O, O, O, O, O, O, O, O,...|[B-ORG, O, O, O, O, O, O, O, O, O, O,...|\n",
            "|[Hussain, ,, considered, surplus, to,...|[B-PER, O, O, O, O, B-LOC, O, O, O, O...|[B-PER, O, O, O, O, B-LOC, O, O, O, O...|\n",
            "|[By, the, close, Yorkshire, had, turn...|[O, O, O, B-ORG, O, O, O, O, O, O, O,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[At, the, Oval, ,, Surrey, captain, C...|[O, O, B-LOC, O, B-ORG, O, B-PER, I-P...|[O, O, O, O, B-ORG, O, B-PER, I-PER, ...|\n",
            "|[He, was, well, backed, by, England, ...|[O, O, O, O, O, B-LOC, O, B-PER, I-PE...|[O, O, O, O, O, B-LOC, O, B-PER, I-PE...|\n",
            "|[Derbyshire, kept, up, the, hunt, for...|[B-ORG, O, O, O, O, O, O, O, O, O, O,...|[B-ORG, O, O, O, O, O, O, O, O, O, O,...|\n",
            "|[Australian, Tom, Moody, took, six, f...|[B-MISC, B-PER, I-PER, O, O, O, O, O,...|[B-MISC, B-PER, I-PER, O, O, O, O, O,...|\n",
            "|[After, the, frustration, of, seeing,...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|[O, O, O, O, O, O, O, O, O, O, O, O, ...|\n",
            "|[They, were, held, up, by, a, gritty,...|[O, O, O, O, O, O, O, O, O, B-PER, I-...|[O, O, O, O, O, O, O, O, O, B-PER, I-...|\n",
            "|[By, stumps, Kent, had, reached, 108,...|         [O, O, B-ORG, O, O, O, O, O, O]|     [O, B-PER, I-PER, O, O, O, O, O, O]|\n",
            "|[CRICKET, -, ENGLISH, COUNTY, CHAMPIO...|    [O, O, B-MISC, I-MISC, I-MISC, O, O]|         [O, O, B-MISC, I-MISC, O, O, O]|\n",
            "|                    [LONDON, 1996-08-30]|                              [B-LOC, O]|                              [B-LOC, O]|\n",
            "|[Result, and, close, of, play, scores...|[O, O, O, O, O, O, O, B-MISC, O, O, O...|[O, O, O, O, O, O, O, B-MISC, O, O, O...|\n",
            "|[Leicester, :, Leicestershire, beat, ...|[B-LOC, O, B-ORG, O, B-ORG, O, O, O, ...|[B-ORG, O, B-ORG, O, B-ORG, O, O, O, ...|\n",
            "+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzC5CDUwM6OS",
        "outputId": "aa8184df-35eb-4163-cfdc-7380840f0695"
      },
      "source": [
        "predictions.printSchema()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sentence: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- label: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- bert: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- ner: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzYP3TGfM6OT",
        "outputId": "9b692463-f59f-41bb-bdc5-08a605e92d13"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|B-ORG       |B-ORG     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |B-LOC       |B-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |B-MISC      |B-MISC    |\n",
            "|Indian        |I-MISC      |I-MISC    |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |B-PER       |B-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjaahMbzuV4A"
      },
      "source": [
        "# Convert to Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "z-M0PZd6M6OU",
        "outputId": "99aab28b-ede5-4fce-803b-928750fb4320"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = predictions.select('token.result','label.result','ner.result').toPandas()\n",
        "\n",
        "df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>result</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...</td>\n",
              "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[LONDON, 1996-08-30]</td>\n",
              "      <td>[B-LOC, O]</td>\n",
              "      <td>[B-LOC, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[West, Indian, all-rounder, Phil, Simmons, too...</td>\n",
              "      <td>[B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...</td>\n",
              "      <td>[B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Their, stay, on, top, ,, though, ,, may, be, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[After, bowling, Somerset, out, for, 83, on, t...</td>\n",
              "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O, B-LOC, I...</td>\n",
              "      <td>[O, O, B-ORG, O, O, O, O, O, O, O, O, B-LOC, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3245</th>\n",
              "      <td>[But, the, prices, may, move, in, a, close, ra...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3246</th>\n",
              "      <td>[Brokers, said, blue, chips, like, IDLC, ,, Ba...</td>\n",
              "      <td>[O, O, O, O, O, B-ORG, O, B-ORG, I-ORG, O, B-O...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-LOC, O, O, B-ORG, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3247</th>\n",
              "      <td>[They, said, there, was, still, demand, for, b...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3248</th>\n",
              "      <td>[The, DSE, all, share, price, index, closed, 2...</td>\n",
              "      <td>[O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3249</th>\n",
              "      <td>[--, Dhaka, Newsroom, 880-2-506363]</td>\n",
              "      <td>[O, B-ORG, I-ORG, O]</td>\n",
              "      <td>[O, B-LOC, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3250 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 result  ...                                             result\n",
              "0     [CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, T...  ...              [O, O, B-ORG, O, O, O, O, O, O, O, O]\n",
              "1                                  [LONDON, 1996-08-30]  ...                                         [B-LOC, O]\n",
              "2     [West, Indian, all-rounder, Phil, Simmons, too...  ...  [B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, ...\n",
              "3     [Their, stay, on, top, ,, though, ,, may, be, ...  ...  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...\n",
              "4     [After, bowling, Somerset, out, for, 83, on, t...  ...  [O, O, B-ORG, O, O, O, O, O, O, O, O, B-LOC, I...\n",
              "...                                                 ...  ...                                                ...\n",
              "3245  [But, the, prices, may, move, in, a, close, ra...  ...   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]\n",
              "3246  [Brokers, said, blue, chips, like, IDLC, ,, Ba...  ...  [O, O, O, O, O, O, O, B-LOC, O, O, B-ORG, O, O...\n",
              "3247  [They, said, there, was, still, demand, for, b...  ...  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
              "3248  [The, DSE, all, share, price, index, closed, 2...  ...  [O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O...\n",
              "3249                [--, Dhaka, Newsroom, 880-2-506363]  ...                                   [O, B-LOC, O, O]\n",
              "\n",
              "[3250 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N47oS8WM6OY"
      },
      "source": [
        "## Prediction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMRW44DM6OY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c3b234-789a-4fbe-cc8e-654f3e4cec0d"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "bert = BertEmbeddings.pretrained('small_bert_L2_128', 'en') \\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        " .setCaseSensitive(True)\n",
        "\n",
        "loaded_ner_model = NerDLModel.load(\"NER_bert_20200219\")\\\n",
        " .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        " .setOutputCol(\"ner\")\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "ner_prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        bert,\n",
        "        loaded_ner_model,\n",
        "        converter])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_bert_L2_128 download started this may take some time.\n",
            "Approximate size to download 16.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmtzkvh0M6OZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b98e77d-178f-4fcb-db77-8218aec284d4"
      },
      "source": [
        "empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "empty_data.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|text|\n",
            "+----+\n",
            "|    |\n",
            "+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ntORrdM6OZ"
      },
      "source": [
        "prediction_model = ner_prediction_pipeline.fit(empty_data)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6hxHQBLM6OZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6759ec0c-be00-4ee2-f37c-365c0413c5f9"
      },
      "source": [
        "text = \"Peter Parker is a nice guy and lives in New York.\"\n",
        "sample_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "sample_data.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Peter Parker is a...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os-XoJCtM6Oa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc13ddb-48d1-4516-b021-c1bd1c2633e1"
      },
      "source": [
        "\n",
        "preds = prediction_model.transform(sample_data)\n",
        "\n",
        "preds.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+\n",
            "|                text|            document|            sentence|               token|                bert|                 ner|ner_span|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+\n",
            "|Peter Parker is a...|[[document, 0, 48...|[[document, 0, 48...|[[token, 0, 4, Pe...|[[word_embeddings...|[[named_entity, 0...|      []|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flcEnI6BM6Oa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768e8788-9f5b-4703-be80-ac80dcf07c0a"
      },
      "source": [
        "preds.select('ner_span.result').take(1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(result=[])]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95ryt1wEM6Oa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7c900a-720b-471c-d82e-6d8211dc4ce1"
      },
      "source": [
        "\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|chunk|entity|\n",
            "+-----+------+\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT2ojwJHM6Oa"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "loaded_ner_model = NerDLModel.load(\"NER_bert_20200219\")\\\n",
        " .setInputCols([\"sentence\", \"token\", \"glove\"])\\\n",
        " .setOutputCol(\"ner\")\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "glove_ner_prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        # glove,\n",
        "        loaded_ner_model,\n",
        "        converter])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw71QpnXM6Ob"
      },
      "source": [
        "glove_prediction_model = glove_ner_prediction_pipeline.fit(empty_data)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqCcz7rwM6Ob"
      },
      "source": [
        "\n",
        "# preds = glove_prediction_model.transform(sample_data)\n",
        "\n",
        "# preds.show()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsoWGO7MM6Ob"
      },
      "source": [
        "\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWIys6BM6Ob"
      },
      "source": [
        "### Pretrained Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOP1riCCM6Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2f8954-6e70-42ca-dd15-5825a6fd8878"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "pretrained_pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')\n",
        "\n",
        "#onto_recognize_entities_sm\n",
        "#explain_document_dl"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 160.1 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdh4U83kM6Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fb617d-7809-459e-866b-b612d60e8d85"
      },
      "source": [
        "text = \"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\n",
        "\n",
        "result = pretrained_pipeline.annotate(text)\n",
        "\n",
        "list(zip(result['token'], result['ner']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'O'),\n",
              " ('Mona', 'B-PER'),\n",
              " ('Lisa', 'I-PER'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('16th', 'O'),\n",
              " ('century', 'O'),\n",
              " ('oil', 'O'),\n",
              " ('painting', 'O'),\n",
              " ('created', 'O'),\n",
              " ('by', 'O'),\n",
              " ('Leonardo', 'B-PER'),\n",
              " ('.', 'O'),\n",
              " (\"It's\", 'O'),\n",
              " ('held', 'O'),\n",
              " ('at', 'O'),\n",
              " ('the', 'O'),\n",
              " ('Louvre', 'B-LOC'),\n",
              " ('in', 'O'),\n",
              " ('Paris', 'B-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-F-QJzCM6Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa45506e-02be-4c7c-cf62-fa88b63d367c"
      },
      "source": [
        "pretrained_pipeline2 = PretrainedPipeline('explain_document_dl', lang='en')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explain_document_dl download started this may take some time.\n",
            "Approx size to download 169.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da9Ql6-hM6Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958c4c5b-dc2c-44bd-8a53-2b41a7332a4e"
      },
      "source": [
        "text = \"The Mona Lisa is a 16th centry oil painting created by Leonrdo. It's held at the Louvre in Paris.\"\n",
        "\n",
        "result2 = pretrained_pipeline2.annotate(text)\n",
        "\n",
        "result2\n",
        "list(zip(result2['token'],  result2['checked'], result2['pos'], result2['ner'],  result2['lemma'],  result2['stem']))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'The', 'DT', 'O', 'The', 'the'),\n",
              " ('Mona', 'Mona', 'NNP', 'B-PER', 'Mona', 'mona'),\n",
              " ('Lisa', 'Lisa', 'NNP', 'I-PER', 'Lisa', 'lisa'),\n",
              " ('is', 'is', 'VBZ', 'O', 'be', 'i'),\n",
              " ('a', 'a', 'DT', 'O', 'a', 'a'),\n",
              " ('16th', '6th', 'JJ', 'O', '6th', '6th'),\n",
              " ('centry', 'centry', 'NN', 'O', 'centry', 'centri'),\n",
              " ('oil', 'oil', 'NN', 'O', 'oil', 'oil'),\n",
              " ('painting', 'painting', 'NN', 'O', 'painting', 'paint'),\n",
              " ('created', 'created', 'VBN', 'O', 'create', 'creat'),\n",
              " ('by', 'by', 'IN', 'O', 'by', 'by'),\n",
              " ('Leonrdo', 'Leonardo', 'NNP', 'B-ORG', 'Leonardo', 'leonardo'),\n",
              " ('.', '.', '.', 'O', '.', '.'),\n",
              " (\"It's\", 'Itys', 'NNP', 'O', 'Itys', 'iti'),\n",
              " ('held', 'held', 'VBD', 'O', 'hold', 'held'),\n",
              " ('at', 'at', 'IN', 'O', 'at', 'at'),\n",
              " ('the', 'the', 'DT', 'O', 'the', 'the'),\n",
              " ('Louvre', 'Louvre', 'NNP', 'B-LOC', 'Louvre', 'louvr'),\n",
              " ('in', 'in', 'IN', 'O', 'in', 'in'),\n",
              " ('Paris', 'Paris', 'NNP', 'B-LOC', 'Paris', 'pari'),\n",
              " ('.', '.', '.', 'O', '.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UotW3Nr_M6Od"
      },
      "source": [
        "xx= pretrained_pipeline2.fullAnnotate(text)\n",
        "\n",
        "#[(n.result, n.metadata['entity']) for n in xx['ner_span']]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbY3ZstAM6OV"
      },
      "source": [
        "### with Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40YZFzD6M6OW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aabfec5-cc44-41dc-b8b9-b58b6184d9c9"
      },
      "source": [
        "glove = WordEmbeddingsModel().pretrained() \\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        " .setOutputCol(\"glove\")\\\n",
        " .setCaseSensitive(False)\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "\n",
        "test_data = glove.transform(test_data.limit(1000))\n",
        "\n",
        "test_data.write.parquet(\"test_withGloveEmbeds.parquet\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygjYFiZMM6OW"
      },
      "source": [
        "nerTagger.setInputCols([\"sentence\", \"token\", \"glove\"])\n",
        "nerTagger.setTestDataset(\"test_withGloveEmbeds.parquet\")\n",
        "\n",
        "glove_pipeline = Pipeline(\n",
        "    stages = [\n",
        "    glove,\n",
        "    nerTagger\n",
        "  ])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJLeqlq3M6OW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a36fb95-362f-4809-bfb3-e856305330eb"
      },
      "source": [
        "%%time\n",
        "\n",
        "ner_model_v3 = glove_pipeline.fit(training_data.limit(1000))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 546 ms, sys: 65.8 ms, total: 612 ms\n",
            "Wall time: 1min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix0O0YPwM6OX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df33f48-973a-4d7a-e4ce-ec5281bbb5f6"
      },
      "source": [
        "predictions_v3 = ner_model_v3.transform(test_data.limit(10))\n",
        "\n",
        "# test_data.sample(False,0.1,0)\n",
        "\n",
        "predictions_v3.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|B-ORG       |B-ORG     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |B-LOC       |B-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |B-MISC      |B-LOC     |\n",
            "|Indian        |I-MISC      |O         |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |B-PER       |B-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26z4CW7QM6OX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a6657a-e873-42ec-9baf-a167ca45e2ac"
      },
      "source": [
        "import numpy as np\n",
        "np.array (predictions.select('token.result').take(1))[0][0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CRICKET', '-', 'LEICESTERSHIRE', 'TAKE', 'OVER', 'AT', 'TOP',\n",
              "       'AFTER', 'INNINGS', 'VICTORY', '.'], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGZjA_pBM6OX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "d80701c7-5117-414a-fa6b-1d87719ce94b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tokens = np.array (predictions.select('token.result').take(1))[0][0]\n",
        "ground = np.array (predictions.select('label.result').take(1))[0][0]\n",
        "label_bert_0 = np.array (predictions.select('ner.result').take(1))[0][0]\n",
        "#label_bert_2 = np.array (predictions_v2.select('ner.result').take(1))[0][0]\n",
        "label_glove = np.array (predictions_v3.select('ner.result').take(1))[0][0]\n",
        "\n",
        "pd.DataFrame({'token':tokens,\n",
        "              'ground':ground,\n",
        "              'label_bert_0':label_bert_0,\n",
        "              'label_glove':label_glove})\n",
        "#'label_bert_2':label_bert_2"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>ground</th>\n",
              "      <th>label_bert_0</th>\n",
              "      <th>label_glove</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRICKET</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LEICESTERSHIRE</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TAKE</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OVER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AT</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TOP</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AFTER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>INNINGS</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>VICTORY</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             token ground label_bert_0 label_glove\n",
              "0          CRICKET      O            O           O\n",
              "1                -      O            O           O\n",
              "2   LEICESTERSHIRE  B-ORG            O       B-ORG\n",
              "3             TAKE      O            O           O\n",
              "4             OVER      O            O           O\n",
              "5               AT      O            O           O\n",
              "6              TOP      O            O           O\n",
              "7            AFTER      O            O           O\n",
              "8          INNINGS      O            O           O\n",
              "9          VICTORY      O            O           O\n",
              "10               .      O            O           O"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwAHj6mPM6Od"
      },
      "source": [
        "## Using your own custom Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC8RR7iXM6Od"
      },
      "source": [
        "custom_embeddings = WordEmbeddings()\\\n",
        "  .setInputCols([\"sentence\", \"token\"])\\\n",
        "  .setOutputCol(\"glove\")\\\n",
        "  .setStoragePath('/Users/vkocaman/cache_pretrained/PubMed-shuffle-win-2.bin', \"BINARY\")\\\n",
        ".setDimension(200)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVkJgZnRM6Od"
      },
      "source": [
        "#custom_embeddings.fit(training_data.limit(10)).transform(training_data.limit(10)).show()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKp_pARIM6Oe"
      },
      "source": [
        "## creating your own CoNLL dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdCxFU2HM6Oe"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "def get_ann_pipeline ():\n",
        "    \n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"text\")\\\n",
        "        .setOutputCol('document')\n",
        "\n",
        "    sentence = SentenceDetector()\\\n",
        "        .setInputCols(['document'])\\\n",
        "        .setOutputCol('sentence')\\\n",
        "        .setCustomBounds(['\\n'])\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"sentence\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    pos = PerceptronModel.pretrained() \\\n",
        "              .setInputCols([\"sentence\", \"token\"]) \\\n",
        "              .setOutputCol(\"pos\")\n",
        "    \n",
        "    embeddings = WordEmbeddingsModel.pretrained()\\\n",
        "          .setInputCols([\"sentence\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "\n",
        "    ner_model = NerDLModel.pretrained() \\\n",
        "          .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "    ner_pipeline = Pipeline(\n",
        "        stages = [\n",
        "            document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            pos,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "    ner_pipelineFit = ner_pipeline.fit(empty_data)\n",
        "\n",
        "    ner_lp_pipeline = LightPipeline(ner_pipelineFit)\n",
        "\n",
        "    print (\"Spark NLP NER lightpipeline is created\")\n",
        "\n",
        "    return ner_lp_pipeline\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMgY0pEhM6Oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142f0bed-faab-42ef-d7bc-c36fd6d10c6a"
      },
      "source": [
        "conll_pipeline = get_ann_pipeline ()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.6 MB\n",
            "[OK!]\n",
            "Spark NLP NER lightpipeline is created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aYv-WM1M6Oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f973fc06-b93b-403b-f1cd-a29476ff8b07"
      },
      "source": [
        "parsed = conll_pipeline.annotate (\"Peter Parker is a nice guy and lives in New York.\")\n",
        "parsed"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['Peter Parker is a nice guy and lives in New York.'],\n",
              " 'embeddings': ['Peter',\n",
              "  'Parker',\n",
              "  'is',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'guy',\n",
              "  'and',\n",
              "  'lives',\n",
              "  'in',\n",
              "  'New',\n",
              "  'York',\n",
              "  '.'],\n",
              " 'ner': ['B-PER',\n",
              "  'I-PER',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-LOC',\n",
              "  'I-LOC',\n",
              "  'O'],\n",
              " 'ner_chunk': ['Peter Parker', 'New York'],\n",
              " 'pos': ['NNP',\n",
              "  'NNP',\n",
              "  'VBZ',\n",
              "  'DT',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  'CC',\n",
              "  'NNS',\n",
              "  'IN',\n",
              "  'NNP',\n",
              "  'NNP',\n",
              "  '.'],\n",
              " 'sentence': ['Peter Parker is a nice guy and lives in New York.'],\n",
              " 'token': ['Peter',\n",
              "  'Parker',\n",
              "  'is',\n",
              "  'a',\n",
              "  'nice',\n",
              "  'guy',\n",
              "  'and',\n",
              "  'lives',\n",
              "  'in',\n",
              "  'New',\n",
              "  'York',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNpOPXUSM6Of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcaa2fde-8d60-4f58-86dc-c0f6d855d79f"
      },
      "source": [
        "conll_lines=''\n",
        "\n",
        "for token, pos, ner in zip(parsed['token'],parsed['pos'],parsed['ner']):\n",
        "\n",
        "    conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, ner)\n",
        "\n",
        "\n",
        "print(conll_lines)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peter NNP NNP B-PER\n",
            "Parker NNP NNP I-PER\n",
            "is VBZ VBZ O\n",
            "a DT DT O\n",
            "nice JJ JJ O\n",
            "guy NN NN O\n",
            "and CC CC O\n",
            "lives NNS NNS O\n",
            "in IN IN O\n",
            "New NNP NNP B-LOC\n",
            "York NNP NNP I-LOC\n",
            ". . . O\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfKkZheoM6Of"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    }
  ]
}