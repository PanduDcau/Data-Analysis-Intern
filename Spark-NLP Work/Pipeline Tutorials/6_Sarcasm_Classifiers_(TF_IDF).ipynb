{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "6- Sarcasm Classifiers (TF-IDF).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMIzQmfw78CG"
      },
      "source": [
        "![](https://memesbams.com/wp-content/uploads/2017/11/sheldon-sarcasm-meme.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqoQqxpE78CN"
      },
      "source": [
        "https://www.kaggle.com/danofer/sarcasm\n",
        "<div class=\"markdown-converter__text--rendered\"><h3>Context</h3>\n",
        "\n",
        "<p>This dataset contains 1.3 million Sarcastic comments from the Internet commentary website Reddit. The dataset was generated by scraping comments from Reddit (not by me :)) containing the <code>\\s</code> ( sarcasm) tag. This tag is often used by Redditors to indicate that their comment is in jest and not meant to be taken seriously, and is generally a reliable indicator of sarcastic comment content.</p>\n",
        "\n",
        "<h3>Content</h3>\n",
        "\n",
        "<p>Data has balanced and imbalanced (i.e true distribution) versions. (True ratio is about 1:100). The\n",
        "corpus has 1.3 million sarcastic statements, along with what they responded to as well as many non-sarcastic comments from the same source.</p>\n",
        "\n",
        "<p>Labelled comments are in the <code>train-balanced-sarcasm.csv</code> file.</p>\n",
        "\n",
        "<h3>Acknowledgements</h3>\n",
        "\n",
        "<p>The data was gathered by: Mikhail Khodak and Nikunj Saunshi and Kiran Vodrahalli for their article \"<a href=\"https://arxiv.org/abs/1704.05579\" rel=\"nofollow\">A Large Self-Annotated Corpus for Sarcasm</a>\". The data is hosted <a href=\"http://nlp.cs.princeton.edu/SARC/0.0/\" rel=\"nofollow\">here</a>.</p>\n",
        "\n",
        "<p>Citation:</p>\n",
        "\n",
        "<pre><code>@unpublished{SARC,\n",
        "  authors={Mikhail Khodak and Nikunj Saunshi and Kiran Vodrahalli},\n",
        "  title={A Large Self-Annotated Corpus for Sarcasm},\n",
        "  url={https://arxiv.org/abs/1704.05579},\n",
        "  year=2017\n",
        "}\n",
        "</code></pre>\n",
        "\n",
        "<p><a href=\"http://nlp.cs.princeton.edu/SARC/0.0/readme.txt\" rel=\"nofollow\">Annotation of files in the original dataset: readme.txt</a>.</p>\n",
        "\n",
        "<h3>Inspiration</h3>\n",
        "\n",
        "<ul>\n",
        "<li>Predicting sarcasm and relevant NLP features (e.g. subjective determinant, racism, conditionals, sentiment heavy words, \"Internet Slang\" and specific phrases). </li>\n",
        "<li>Sarcasm vs Sentiment</li>\n",
        "<li>Unusual linguistic features such as caps, italics, or elongated words. e.g., \"Yeahhh, I'm sure THAT is the right answer\".</li>\n",
        "<li>Topics that people tend to react to sarcastically</li>\n",
        "</ul></div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHHSqpAJ8FWj",
        "outputId": "63d9ab2d-56f2-4d59-d790-bce690368859"
      },
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 65 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 19.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 37.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmTDxdmk78CQ"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import sparknlp\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\") \\\n",
        "    .master(\"local[8]\") \\\n",
        "    .config(\"spark.driver.memory\",\"6G\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"1G\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"800M\")\\\n",
        "    .config(\"spark.jars.packages\", 'com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.0') \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2tYOxGn78CR",
        "outputId": "8c219544-fe27-4d38-8f99-e76c01e2ca73"
      },
      "source": [
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.3.4\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUkV0wKO78CT",
        "outputId": "816bddbb-6933-4e1b-94eb-ee84b21ed957"
      },
      "source": [
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv -P /tmp"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 07:08:19--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.169.96\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.169.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘/tmp/train-balanced-sarcasm.csv’ not modified on server. Omitting download.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9GgNJ2778CV",
        "outputId": "afcfd640-883e-4036-9f85-ee39766018d6"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "\n",
        "sql = SQLContext(spark)\n",
        "\n",
        "trainBalancedSarcasmDF = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/tmp/train-balanced-sarcasm.csv\")\n",
        "trainBalancedSarcasmDF.printSchema()\n",
        "\n",
        "# Let's create a temp view (table) for our SQL queries\n",
        "trainBalancedSarcasmDF.createOrReplaceTempView('data')\n",
        "\n",
        "sql.sql('SELECT COUNT(*) FROM data').collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- comment: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            " |-- subreddit: string (nullable = true)\n",
            " |-- score: string (nullable = true)\n",
            " |-- ups: string (nullable = true)\n",
            " |-- downs: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- created_utc: string (nullable = true)\n",
            " |-- parent_comment: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(count(1)=1010826)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pGiBySS78CW",
        "outputId": "b02409ea-a025-486c-be49-b34ce240eae9"
      },
      "source": [
        "sql.sql('select * from data limit 20').show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------------------+------------------+-----+---+-----+-------+-------------------+--------------------+\n",
            "|label|             comment|            author|         subreddit|score|ups|downs|   date|        created_utc|      parent_comment|\n",
            "+-----+--------------------+------------------+------------------+-----+---+-----+-------+-------------------+--------------------+\n",
            "|    0|          NC and NH.|         Trumpbart|          politics|    2| -1|   -1|2016-10|2016-10-16 23:55:23|Yeah, I get that ...|\n",
            "|    0|You do know west ...|         Shbshb906|               nba|   -4| -1|   -1|2016-11|2016-11-01 00:24:10|The blazers and M...|\n",
            "|    0|They were underdo...|          Creepeth|               nfl|    3|  3|    0|2016-09|2016-09-22 21:45:37|They're favored t...|\n",
            "|    0|\"This meme isn't ...|         icebrotha|BlackPeopleTwitter|   -8| -1|   -1|2016-10|2016-10-18 21:03:47|deadass don't kil...|\n",
            "|    0|I could use one o...|         cush2push|MaddenUltimateTeam|    6| -1|   -1|2016-12|2016-12-30 17:00:13|Yep can confirm I...|\n",
            "|    0|I don't pay atten...|       only7inches|         AskReddit|    0|  0|    0|2016-09|2016-09-02 10:35:08|do you find arian...|\n",
            "|    0|Trick or treating...|       only7inches|         AskReddit|    1| -1|   -1|2016-10|2016-10-23 21:43:03|What's your weird...|\n",
            "|    0|Blade Mastery+Mas...|         P0k3rm4s7|     FFBraveExvius|    2| -1|   -1|2016-10|2016-10-13 21:13:55|Probably Sephirot...|\n",
            "|    0|You don't have to...|        SoupToPots|      pcmasterrace|    1| -1|   -1|2016-10|2016-10-27 19:11:06|What to upgrade? ...|\n",
            "|    0|I would love to s...|          chihawks|      Lollapalooza|    2| -1|   -1|2016-11|2016-11-21 23:39:12|Probably count Ka...|\n",
            "|    0|I think a signifi...|ThisIsNotKimJongUn|          politics|   92| 92|    0|2016-09|2016-09-20 17:53:52|I bet if that mon...|\n",
            "|    0|Damn I was hoping...|        Kvetch__22|          baseball|   14| -1|   -1|2016-10|2016-10-28 09:07:50|James Shields Wil...|\n",
            "|    0|They have an agenda.|        Readbooks6|          exmormon|    4| -1|   -1|2016-10|2016-10-15 01:14:03|There's no time t...|\n",
            "|    0|         Great idea!|        pieman2005|   fantasyfootball|    1| -1|   -1|2016-10|2016-10-06 23:27:53|Team Specific Thr...|\n",
            "|    0|Ayy bb wassup, it...|      Jakethejoker|          NYGiants|   29| 29|    0|2016-09|2016-09-19 18:46:58|Ill give you a hi...|\n",
            "|    0|       what the fuck|            Pishwi|         AskReddit|   22| -1|   -1|2016-11|2016-11-04 20:10:33|Star Wars, easy. ...|\n",
            "|    0|              noted.|         kozmo1313|        NewOrleans|    2| -1|   -1|2016-12|2016-12-20 21:59:45|    You're adorable.|\n",
            "|    0|because it's what...|         kozmo1313|          politics|   15| -1|   -1|2016-12|2016-12-26 20:10:45|He actually acts ...|\n",
            "|    0|why you fail me, ...|         kozmo1313|  HillaryForPrison|    1|  1|    0|2016-09|2016-09-18 13:02:45|Clinton struggles...|\n",
            "|    0|Pre-Flashpoint Cl...|   BreakingGarrick|          superman|    2|  2|    0|2016-09|2016-09-16 02:34:04|Is that the Older...|\n",
            "+-----+--------------------+------------------+------------------+-----+---+-----+-------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKL1V_bX78CW",
        "outputId": "2f710605-c634-4167-d59f-4a2d008ac949"
      },
      "source": [
        "sql.sql('select label,count(*) as cnt from data group by label order by cnt desc').show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|label|   cnt|\n",
            "+-----+------+\n",
            "|    1|505413|\n",
            "|    0|505413|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDCwXymO78CX",
        "outputId": "7af4c772-bc43-4754-8ae5-56c23b867e92"
      },
      "source": [
        "sql.sql('select count(*) from data where comment is null').collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(count(1)=53)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzqL8ZgG78CY",
        "outputId": "3b916e6a-7b2b-4881-b08d-8c0605a92f7f"
      },
      "source": [
        "df = sql.sql('select label,concat(parent_comment,\"\\n\",comment) as comment from data where comment is not null and parent_comment is not null limit 100000')\n",
        "print(type(df))\n",
        "df.printSchema()\n",
        "print(\"Amount of rows:\", df.count())\n",
        "df = df.limit(2000) #minimize dataset if you are not running on a cluster\n",
        "df.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- comment: string (nullable = true)\n",
            "\n",
            "Amount of rows: 100000\n",
            "+-----+--------------------+\n",
            "|label|             comment|\n",
            "+-----+--------------------+\n",
            "|    0|Yeah, I get that ...|\n",
            "|    0|The blazers and M...|\n",
            "|    0|They're favored t...|\n",
            "|    0|deadass don't kil...|\n",
            "|    0|Yep can confirm I...|\n",
            "|    0|do you find arian...|\n",
            "|    0|What's your weird...|\n",
            "|    0|Probably Sephirot...|\n",
            "|    0|What to upgrade? ...|\n",
            "|    0|Probably count Ka...|\n",
            "|    0|I bet if that mon...|\n",
            "|    0|James Shields Wil...|\n",
            "|    0|There's no time t...|\n",
            "|    0|Team Specific Thr...|\n",
            "|    0|Ill give you a hi...|\n",
            "|    0|Star Wars, easy. ...|\n",
            "|    0|You're adorable.\n",
            "...|\n",
            "|    0|He actually acts ...|\n",
            "|    0|Clinton struggles...|\n",
            "|    0|Is that the Older...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khsb-PM9oE4"
      },
      "source": [
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id8cR8Ej78CY"
      },
      "source": [
        "# from sparknlp.annotator import *\n",
        "# from sparknlp.common import *\n",
        "# from sparknlp.base import *\n",
        "\n",
        "# documentAssembler = DocumentAssembler()\\\n",
        "#     .setInputCol(\"text\")\\\n",
        "#     .setOutputCol(\"document\")\n",
        "\n",
        "# tokenizer = Tokenizer() \\\n",
        "#     .setInputCols([\"document\"]) \\\n",
        "#     .setOutputCol(\"token\")\n",
        "\n",
        "# stemmer = Stemmer() \\\n",
        "#     .setInputCols([\"token\"]) \\\n",
        "#     .setOutputCol(\"stem\")\n",
        "\n",
        "    \n",
        "# sentence_detector = SentenceDetector() \\\n",
        "#     .setInputCols([\"document\"]) \\\n",
        "#     .setOutputCol(\"sentence\") \\\n",
        "#     .setUseAbbreviations(True)\n",
        "\n",
        "# normalizer = Normalizer() \\\n",
        "#     .setInputCols([\"stem\"]) \\\n",
        "#     .setOutputCol(\"normalized\")\n",
        "\n",
        "# finisher = Finisher() \\\n",
        "#     .setInputCols([\"normalized\"]) \\\n",
        "#     .setOutputCols([\"ntokens\"]) \\\n",
        "#     .setOutputAsArray(True) \\\n",
        "#     .setCleanAnnotations(True)\n",
        "\n",
        "# nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, stemmer, normalizer, finisher])\n",
        "# nlp_model = nlp_pipeline.fit(df)\n",
        "# processed = nlp_model.transform(df).persist()\n",
        "# processed.count()\n",
        "# processed.show()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNyiySVO78CZ",
        "outputId": "f8a3702c-c52e-4d6e-be5e-0cd3698a0416"
      },
      "source": [
        "train, test = processed.randomSplit(weights=[0.7, 0.3], seed=123)\n",
        "print(train.count())\n",
        "print(test.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1401\n",
            "599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO4aI9zz78CZ",
        "outputId": "dc302424-ee19-4191-ccfa-9de6f891e260"
      },
      "source": [
        "from pyspark.ml import feature as spark_ft\n",
        "\n",
        "stopWords = spark_ft.StopWordsRemover.loadDefaultStopWords('english')\n",
        "sw_remover = spark_ft.StopWordsRemover(inputCol='ntokens', outputCol='clean_tokens', stopWords=stopWords)\n",
        "tf = spark_ft.CountVectorizer(vocabSize=500, inputCol='clean_tokens', outputCol='tf')\n",
        "idf = spark_ft.IDF(minDocFreq=5, inputCol='tf', outputCol='idf')\n",
        "\n",
        "feature_pipeline = Pipeline(stages=[sw_remover, tf, idf])\n",
        "feature_model = feature_pipeline.fit(train)\n",
        "\n",
        "train_featurized = feature_model.transform(train).persist()\n",
        "train_featurized.count()\n",
        "train_featurized.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|label|             comment|             ntokens|        clean_tokens|                  tf|                 idf|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    0|\"\"\"Agreed. I thin...|[agr, i, think, w...|[agr, think, issu...|(500,[0,1,7,9,31,...|(500,[0,1,7,9,31,...|\n",
            "|    0|\"\"\"It's kind of h...|[it, kind, of, ha...|[kind, hard, turn...|(500,[4,6,133,135...|(500,[4,6,133,135...|\n",
            "|    0|\"\"\"Mom\n",
            "Holy shitb...|[mom, holi, shitb...|[mom, holi, shitb...|(500,[414,484],[1...|(500,[414,484],[5...|\n",
            "|    0|\"\"\"People\"\"\n",
            "Umm, ...|[peopl, umm, he, ...|[peopl, umm, cant...|(500,[7,49],[1.0,...|(500,[7,49],[2.44...|\n",
            "|    0|\"\"\"Play it cool; ...|[plai, it, cool, ...|[plai, cool, plai...|(500,[21,57,77,18...|(500,[21,57,77,18...|\n",
            "|    0|\"\"\"Said it last y...|[said, it, last, ...|[said, last, year...|(500,[1,4,19,25,2...|(500,[1,4,19,25,2...|\n",
            "|    0|\"\"\"The Witch\"\" is...|[the, witch, i, c...|[witch, complex, ...|(500,[61,85],[1.0...|(500,[61,85],[3.4...|\n",
            "|    0|\"\"\"The way I see ...|[the, wai, i, see...|[wai, see, liter,...|(500,[23,24,26,92...|(500,[23,24,26,92...|\n",
            "|    0|\"\"\"Tread lightly ...|[tread, lightli, ...|[tread, lightli, ...|         (500,[],[])|         (500,[],[])|\n",
            "|    0|\"\"\"You are like t...|[you, ar, like, t...|[ar, like, end, p...|(500,[0,1,3,11,11...|(500,[0,1,3,11,11...|\n",
            "|    0|\"@Senator_Assange...|[senatorassang, i...|[senatorassang, o...|(500,[0,1,78,93,1...|(500,[0,1,78,93,1...|\n",
            "|    0|\"A quick google s...|[a, quick, googl,...|[quick, googl, se...|(500,[1,4,7,19,27...|(500,[1,4,7,19,27...|\n",
            "|    0|\"Added flair per ...|[ad, flair, per, ...|[ad, flair, per, ...|(500,[6,16,102,11...|(500,[6,16,102,11...|\n",
            "|    0|\"Amazon is coming...|[amazon, i, come,...|[amazon, come, au...|(500,[1,10,56],[1...|(500,[1,10,56],[1...|\n",
            "|    0|\"And yet most of ...|[and, yet, most, ...|[yet, stoner, deg...|(500,[23,30,33,19...|(500,[23,30,33,19...|\n",
            "|    0|\"Another giveaway...|[anoth, giveawai,...|[anoth, giveawai,...|(500,[61,166,360]...|(500,[61,166,360]...|\n",
            "|    0|\"As a person who ...|[a, a, person, wh...|[person, doesnt, ...|(500,[3,7,18,19,3...|(500,[3,7,18,19,3...|\n",
            "|    0|\"BREAKING: Trump ...|[break, trump, ou...|[break, trump, ou...|(500,[4,5,23,29,3...|(500,[4,5,23,29,3...|\n",
            "|    0|\"Bug/Feature? Ver...|[bugfeatur, veri,...|[bugfeatur, veri,...|(500,[12,21,22,38...|(500,[12,21,22,38...|\n",
            "|    0|\"Charlie Kirk: \"\"...|[charli, kirk, if...|[charli, kirk, wa...|(500,[2,23,61,95,...|(500,[2,23,61,95,...|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jscbpwUC78Ca",
        "outputId": "4b934f9e-909a-44a4-ba5b-2418a8a09f00"
      },
      "source": [
        "train_featurized.groupBy(\"label\").count().show()\n",
        "train_featurized.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|    0| 1285|\n",
            "|    1|  116|\n",
            "+-----+-----+\n",
            "\n",
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- comment: string (nullable = true)\n",
            " |-- ntokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- clean_tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- tf: vector (nullable = true)\n",
            " |-- idf: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IlGiSh178Ca"
      },
      "source": [
        "from pyspark.ml import classification as spark_cls\n",
        "\n",
        "rf = spark_cls. RandomForestClassifier(labelCol=\"label\", featuresCol=\"idf\", numTrees=100)\n",
        "\n",
        "model = rf.fit(train_featurized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrsX-a0c78Cb",
        "outputId": "db30b184-40be-443c-8703-61476190038c"
      },
      "source": [
        "test_featurized = feature_model.transform(test)\n",
        "preds = model.transform(test_featurized)\n",
        "preds.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|             comment|             ntokens|        clean_tokens|                  tf|                 idf|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|    0|\"\"\"Did Hillary Cl...|[did, hillari, cl...|[hillari, clinton...|(500,[27,108,158,...|(500,[27,108,158,...|[92.0320732186918...|[0.92032073218691...|       0.0|\n",
            "|    0|\"\"\"Gingrich\n",
            "And C...|[gingrich, and, c...|[gingrich, christ...|(500,[13,107,495]...|(500,[13,107,495]...|[92.6783479665537...|[0.92678347966553...|       0.0|\n",
            "|    0|\"\"\"Hey you wanna ...|[hei, you, wanna,...|[hei, wanna, get,...|(500,[5,6,10,16,7...|(500,[5,6,10,16,7...|[92.2620890672296...|[0.92262089067229...|       0.0|\n",
            "|    0|\"\"\"QR Code\"\"\n",
            "\"For...|[qr, code, for, s...|[qr, code, reason...|(500,[2,26,156],[...|(500,[2,26,156],[...|[92.4972297009707...|[0.92497229700970...|       0.0|\n",
            "|    0|\"\"\"The Germans bo...|[the, german, bom...|[german, bomb, pe...|    (500,[52],[1.0])|(500,[52],[3.2383...|[92.6166281329892...|[0.92616628132989...|       0.0|\n",
            "|    0|\"*Danny reaches f...|[danni, reach, fo...|[danni, reach, wa...|(500,[0,5,8,74,12...|(500,[0,5,8,74,12...|[92.7161168398888...|[0.92716116839888...|       0.0|\n",
            "|    0|\"*Guilt roles ove...|[guilt, role, ove...|[guilt, role, mel...|(500,[13,62,76,22...|(500,[13,62,76,22...|[92.6463729904481...|[0.92646372990448...|       0.0|\n",
            "|    0|\"90% of the time ...|[of, the, time, i...|[time, kid, try, ...|(500,[3,14,15,20,...|(500,[3,14,15,20,...|[91.8639530448285...|[0.91863953044828...|       0.0|\n",
            "|    0|\"Anyone else sort...|[anyon, els, sort...|[anyon, els, sort...|(500,[3,7,8,22,89...|(500,[3,7,8,22,89...|[92.3992599215963...|[0.92399259921596...|       0.0|\n",
            "|    0|\"BU only follows ...|[bu, onli, follow...|[bu, onli, follow...|(500,[4,6,16,19,2...|(500,[4,6,16,19,2...|[92.6166281329892...|[0.92616628132989...|       0.0|\n",
            "|    0|\"Can we have a \"\"...|[can, we, have, a...|[sorri, context, ...|(500,[18,65,88,21...|(500,[18,65,88,21...|[92.3950586150586...|[0.92395058615058...|       0.0|\n",
            "|    0|\"David Sirota on ...|[david, sirota, o...|[david, sirota, t...|(500,[75,108,418,...|(500,[75,108,418,...|[92.2311242616791...|[0.92231124261679...|       0.0|\n",
            "|    0|\"Electrical Engin...|[electr, engin, w...|[electr, engin, e...|(500,[28,199,475]...|(500,[28,199,475]...|[92.6166281329892...|[0.92616628132989...|       0.0|\n",
            "|    0|\"From what I've g...|[from, what, iv, ...|[iv, gather, ar, ...|(500,[0,1,5,54,12...|(500,[0,1,5,54,12...|[92.6658190435815...|[0.92665819043581...|       0.0|\n",
            "|    0|\"Has Persona 5 ma...|[ha, persona, mad...|[ha, persona, mad...|(500,[4,5,7,9,11,...|(500,[4,5,7,9,11,...|[91.6977256313083...|[0.91697725631308...|       0.0|\n",
            "|    0|\"Hey man, no need...|[hei, man, no, ne...|[hei, man, ne, ge...|(500,[2,5,13,61,6...|(500,[2,5,13,61,6...|[92.5777516292268...|[0.92577751629226...|       0.0|\n",
            "|    0|\"I dunno, doesnt ...|[i, dunno, doesnt...|[dunno, doesnt, m...|(500,[3,5,11,13,1...|(500,[3,5,11,13,1...|[91.8928628817710...|[0.91892862881771...|       0.0|\n",
            "|    0|\"I just worry (a ...|[i, just, worri, ...|[worri, littl, bi...|(500,[0,2,3,13,18...|(500,[0,2,3,13,18...|[92.4669727427924...|[0.92466972742792...|       0.0|\n",
            "|    0|\"I like how there...|[i, like, how, th...|[like, ye, decis,...|(500,[1,3,4,8,71,...|(500,[1,3,4,8,71,...|[89.8155734498752...|[0.89815573449875...|       0.0|\n",
            "|    0|\"I like the one w...|[i, like, the, on...|[like, ani, wai, ...|(500,[3,4,14,18,2...|(500,[3,4,14,18,2...|[92.6828270297492...|[0.92682827029749...|       0.0|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3GacjOj78Cb"
      },
      "source": [
        "pred_df = preds.select('comment', 'label', 'prediction').toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09eGz0rG78Cb",
        "outputId": "c7d26897-2f8b-45b5-87c3-ad8224b74b68"
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Did Hillary Clinton break the law?\"\" Chaffe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"\"\"Gingrich\\nAnd Christie will be in charge of...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"\"\"Hey you wanna get highhh\"\"\"\\nOh man, oh man...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\"\"QR Code\"\"\\n\"For some reason my brain was se...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"\"\"The Germans bombed Pearl Harbor\"\" Not sure ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  label  prediction\n",
              "0  \"\"\"Did Hillary Clinton break the law?\"\" Chaffe...      0         0.0\n",
              "1  \"\"\"Gingrich\\nAnd Christie will be in charge of...      0         0.0\n",
              "2  \"\"\"Hey you wanna get highhh\"\"\"\\nOh man, oh man...      0         0.0\n",
              "3  \"\"\"QR Code\"\"\\n\"For some reason my brain was se...      0         0.0\n",
              "4  \"\"\"The Germans bombed Pearl Harbor\"\" Not sure ...      0         0.0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Zbgqjq78Cb",
        "outputId": "3c9f682e-52b6-4eae-deca-a547d34aaeb6"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics as skmetrics\n",
        "pd.DataFrame(\n",
        "    data=skmetrics.confusion_matrix(pred_df['label'], pred_df['prediction']),\n",
        "    columns=['pred ' + l for l in ['0','1']],\n",
        "    index=['true ' + l for l in ['0','1']]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred 0</th>\n",
              "      <th>pred 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true 0</th>\n",
              "      <td>537</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true 1</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pred 0  pred 1\n",
              "true 0     537       0\n",
              "true 1      62       0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggR-YvR678Cc",
        "outputId": "0240d7ba-c7d8-409c-d51b-551d766121a5"
      },
      "source": [
        "print(skmetrics.classification_report(pred_df['label'], pred_df['prediction'], \n",
        "                                      target_names=['0','1']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       537\n",
            "           1       0.00      0.00      0.00        62\n",
            "\n",
            "    accuracy                           0.90       599\n",
            "   macro avg       0.45      0.50      0.47       599\n",
            "weighted avg       0.80      0.90      0.85       599\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vkocaman/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqu3z32e78Cc"
      },
      "source": [
        "spark.stop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}