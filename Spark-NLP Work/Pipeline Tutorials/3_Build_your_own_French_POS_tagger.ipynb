{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "3- Build your own French POS tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG3VatUjnw8M"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCuCeAdjnw8R"
      },
      "source": [
        "# Train POS Tagger in French by Spark NLP\n",
        "### Based on Universal Dependency `UD_French-GSD`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXd0dvNroVDZ",
        "outputId": "97a8c168-2225-45ef-e028-bf8f31cacf2f"
      },
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 65 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 20.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 72.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_5zKjfGoUoe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5_LR7sPnw8R"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "#Spark ML and SQL\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.sql.functions import array_contains\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "#Spark NLP\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import RegexRule\n",
        "from sparknlp.base import DocumentAssembler, Finisher\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv1eX194nw8T"
      },
      "source": [
        "### Let's create a Spark Session for our app"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Usde0XXnw8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c736d7-2113-48e5-f3de-25af380f6dc9"
      },
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.3.4\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC4FIUDlnw8U"
      },
      "source": [
        "Let's prepare our training datasets containing `token_posTag` like `de_DET`. You can download this data set from Amazon S3:\n",
        "\n",
        "```\n",
        "wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D5bxDaDnw8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1a2a9b-1e5d-40a9-d9bf-b677812d661f"
      },
      "source": [
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 06:01:21--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.250.94\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.250.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3565213 (3.4M) [text/plain]\n",
            "Saving to: ‘/tmp/UD_French-GSD_2.3.txt’\n",
            "\n",
            "UD_French-GSD_2.3.t 100%[===================>]   3.40M  21.1MB/s    in 0.2s    \n",
            "\n",
            "2021-12-02 06:01:22 (21.1 MB/s) - ‘/tmp/UD_French-GSD_2.3.txt’ saved [3565213/3565213]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryUluJDMnw8W"
      },
      "source": [
        "from sparknlp.training import POS\n",
        "training_data = POS().readDataset(spark, '/tmp/UD_French-GSD_2.3.txt', '_', 'tags')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rit1D86enw8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33083aeb-dff4-4c08-844b-7001c7ca0c2c"
      },
      "source": [
        "training_data.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                text|            document|                tags|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|Les commotions cé...|[{document, 0, 11...|[{pos, 0, 2, DET,...|\n",
            "|L' œuvre est situ...|[{document, 0, 82...|[{pos, 0, 1, DET,...|\n",
            "|Le comportement d...|[{document, 0, 18...|[{pos, 0, 1, DET,...|\n",
            "|Toutefois , les f...|[{document, 0, 44...|[{pos, 0, 8, ADV,...|\n",
            "|Ismene entre et a...|[{document, 0, 80...|[{pos, 0, 5, PROP...|\n",
            "|je reviendrais av...|[{document, 0, 28...|[{pos, 0, 1, PRON...|\n",
            "|Les forfaits comp...|[{document, 0, 30...|[{pos, 0, 2, DET,...|\n",
            "|Il prévient que d...|[{document, 0, 99...|[{pos, 0, 1, PRON...|\n",
            "|Ils tiraient à ba...|[{document, 0, 43...|[{pos, 0, 2, PRON...|\n",
            "|Le château est en...|[{document, 0, 44...|[{pos, 0, 1, DET,...|\n",
            "|En effet , la bir...|[{document, 0, 10...|[{pos, 0, 1, ADP,...|\n",
            "|Le point final de...|[{document, 0, 15...|[{pos, 0, 1, DET,...|\n",
            "|L' information gé...|[{document, 0, 53...|[{pos, 0, 1, DET,...|\n",
            "|Motivé par la cha...|[{document, 0, 21...|[{pos, 0, 5, VERB...|\n",
            "|Il exploitait un ...|[{document, 0, 12...|[{pos, 0, 1, PRON...|\n",
            "|Plus tard dans la...|[{document, 0, 84...|[{pos, 0, 3, ADV,...|\n",
            "|Ils deviennent al...|[{document, 0, 97...|[{pos, 0, 2, PRON...|\n",
            "|Le chevalier lui ...|[{document, 0, 17...|[{pos, 0, 1, DET,...|\n",
            "|Créée au cours du...|[{document, 0, 15...|[{pos, 0, 4, VERB...|\n",
            "|On ne peut éviter...|[{document, 0, 11...|[{pos, 0, 1, PRON...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5gDFWpcnw8X"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\\\n",
        "    .setExceptions([\"jusqu'\", \"aujourd'hui\", \"États-Unis\", \"lui-même\", \"celui-ci\", \"c'est-à-dire\", \"celle-ci\", \"au-dessus\", \"etc.\", \"sud-est\", \"Royaume-Uni\", \"ceux-ci\", \"au-delà\", \"elle-même\", \"peut-être\", \"sud-ouest\", \"nord-ouest\", \"nord-est\", \"Etats-Unis\", \"Grande-Bretagne\", \"Pays-Bas\", \"eux-mêmes\", \"porte-parole\", \"Notre-Dame\", \"puisqu'\", \"week-end\", \"quelqu'un\", \"celles-ci\", \"chef-lieu\"])\\\n",
        "    .setPrefixPattern(\"\\\\A([^\\\\s\\\\p{L}\\\\d\\\\$\\\\.#]*)\")\\\n",
        "    .setSuffixPattern(\"([^\\\\s\\\\p{L}\\\\d]?)([^\\\\s\\\\p{L}\\\\d]*)\\\\z\")\\\n",
        "    .setInfixPatterns([\n",
        "      \"([\\\\p{L}\\\\w]+'{1})\",\n",
        "      \"([\\\\$#]?\\\\d+(?:[^\\\\s\\\\d]{1}\\\\d+)*)\",\n",
        "      \"((?:\\\\p{L}\\\\.)+)\",\n",
        "      \"((?:\\\\p{L}+[^\\\\s\\\\p{L}]{1})+\\\\p{L}+)\",\n",
        "      \"([\\\\p{L}\\\\w]+)\"\n",
        "    ])\n",
        "\n",
        "posTagger = PerceptronApproach() \\\n",
        "    .setNIterations(1) \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"pos\") \\\n",
        "    .setPosCol(\"tags\")\n",
        "    \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector, \n",
        "    tokenizer,\n",
        "    posTagger\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgHspX6_nw8Y"
      },
      "source": [
        "# Let's train our Pipeline by using our training dataset\n",
        "model = pipeline.fit(training_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tE2UC9pnw8Y"
      },
      "source": [
        "This is our testing DataFrame where we get some sentences in French. We are going to use our trained Pipeline to transform these sentence and predict each token's `Part Of Speech`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjvGOr4Dnw8Z"
      },
      "source": [
        "dfTest = spark.createDataFrame([\n",
        "    \"Je sens qu'entre ça et les films de médecins et scientifiques fous que nous avons déjà vus, nous pourrions emprunter un autre chemin pour l'origine.\",\n",
        "    \"On pourra toujours parler à propos d'Averroès de décentrement du Sujet.\"\n",
        "], StringType()).toDF(\"text\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2UCAjnwnw8Z"
      },
      "source": [
        "predict = model.transform(dfTest)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZByn-chnw8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f24262b-7bcf-4d56-8842-5150ac5f824a"
      },
      "source": [
        "predict.select(\"token.result\", \"pos.result\").show(truncate=50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                            result|                                            result|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "|[Je, sens, qu'entre, ça, et, les, films, de, mé...|[PRON, NOUN, ADP, PRON, CCONJ, DET, NOUN, ADP, ...|\n",
            "|[On, pourra, toujours, parler, à, propos, d'Ave...|[PRON, VERB, ADV, VERB, ADP, NOUN, NOUN, ADP, N...|\n",
            "+--------------------------------------------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkbgYVGqnw8a"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F30e8lmWnw8b"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}