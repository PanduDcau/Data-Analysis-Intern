{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "7- Sarcasm Classifiers (Word2vec and MLP).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrJCmVygkZch",
        "outputId": "a87620b6-2435-4668-f516-95039cbc5d34"
      },
      "source": [
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv -P /tmp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 17:54:15--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.135.120\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.135.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255268960 (243M) [text/csv]\n",
            "Saving to: ‘/tmp/train-balanced-sarcasm.csv’\n",
            "\n",
            "train-balanced-sarc 100%[===================>] 243.44M  40.2MB/s    in 6.5s    \n",
            "\n",
            "2021-12-02 17:54:22 (37.7 MB/s) - ‘/tmp/train-balanced-sarcasm.csv’ saved [255268960/255268960]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QFODHBUkcr8",
        "outputId": "eb4f0d2c-0353-45c4-f286-2e02e42ef6ca"
      },
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 67 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 16.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 52.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCPH9LbkkZcl"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import sparknlp\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\") \\\n",
        "    .master(\"local[8]\") \\\n",
        "    .config(\"spark.driver.memory\",\"6G\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"1G\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"800M\")\\\n",
        "    .config(\"spark.jars.packages\", 'com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.0') \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_CgYZIDkZcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d5fe69-710c-4b6a-b63c-8acdcca20c7e"
      },
      "source": [
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.3.4\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "W7N7pdW4kZcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d992d4-548f-4f91-85b9-3a7d21470c59"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "\n",
        "sql = SQLContext(spark)\n",
        "\n",
        "trainBalancedSarcasmDF = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/tmp/train-balanced-sarcasm.csv\")\n",
        "trainBalancedSarcasmDF.printSchema()\n",
        "\n",
        "# Let's create a temp view (table) for our SQL queries\n",
        "trainBalancedSarcasmDF.createOrReplaceTempView('data')\n",
        "\n",
        "sql.sql('SELECT COUNT(*) FROM data').collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- comment: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            " |-- subreddit: string (nullable = true)\n",
            " |-- score: string (nullable = true)\n",
            " |-- ups: string (nullable = true)\n",
            " |-- downs: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- created_utc: string (nullable = true)\n",
            " |-- parent_comment: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(count(1)=1010826)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KF1PL-DkZco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d6866e-da69-41a3-db16-5eb5b8596a14"
      },
      "source": [
        "df = sql.sql('select label,concat(parent_comment,\"\\n\",comment) as comment from data where comment is not null and parent_comment is not null limit 100000')\n",
        "print(type(df))\n",
        "print(\"Amount of rows:\", df.count())\n",
        "df = df.limit(2000) #minimize dataset if you are not running on a cluster\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "Amount of rows: 100000\n",
            "root\n",
            " |-- label: integer (nullable = true)\n",
            " |-- comment: string (nullable = true)\n",
            "\n",
            "+-----+--------------------+\n",
            "|label|             comment|\n",
            "+-----+--------------------+\n",
            "|    0|Yeah, I get that ...|\n",
            "|    0|The blazers and M...|\n",
            "|    0|They're favored t...|\n",
            "|    0|deadass don't kil...|\n",
            "|    0|Yep can confirm I...|\n",
            "|    0|do you find arian...|\n",
            "|    0|What's your weird...|\n",
            "|    0|Probably Sephirot...|\n",
            "|    0|What to upgrade? ...|\n",
            "|    0|Probably count Ka...|\n",
            "|    0|I bet if that mon...|\n",
            "|    0|James Shields Wil...|\n",
            "|    0|There's no time t...|\n",
            "|    0|Team Specific Thr...|\n",
            "|    0|Ill give you a hi...|\n",
            "|    0|Star Wars, easy. ...|\n",
            "|    0|You're adorable.\n",
            "...|\n",
            "|    0|He actually acts ...|\n",
            "|    0|Clinton struggles...|\n",
            "|    0|Is that the Older...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNMTHvzDkZco"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "# document_assembler = DocumentAssembler() \\\n",
        "#     .setInputCol(\"comment\") \\\n",
        "#     .setOutputCol(\"document\")\n",
        "    \n",
        "# sentence_detector = SentenceDetector() \\\n",
        "#     .setInputCols([\"document\"]) \\\n",
        "#     .setOutputCol(\"sentence\") \\\n",
        "#     .setUseAbbreviations(True)\n",
        "    \n",
        "# tokenizer = Tokenizer() \\\n",
        "#   .setInputCols([\"sentence\"]) \\\n",
        "#   .setOutputCol(\"token\")\n",
        "\n",
        "# stemmer = Stemmer() \\\n",
        "#     .setInputCols([\"token\"]) \\\n",
        "#     .setOutputCol(\"stem\")\n",
        "    \n",
        "# normalizer = Normalizer() \\\n",
        "#     .setInputCols([\"stem\"]) \\\n",
        "#     .setOutputCol(\"normalized\")\n",
        "\n",
        "# finisher = Finisher() \\\n",
        "#     .setInputCols([\"normalized\"]) \\\n",
        "#     .setOutputCols([\"ntokens\"]) \\\n",
        "#     .setOutputAsArray(True) \\\n",
        "#     .setCleanAnnotations(True)\n",
        "\n",
        "# nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, stemmer, normalizer, finisher])\n",
        "# nlp_model = nlp_pipeline.fit(df)\n",
        "# processed = nlp_model.transform(df).persist()\n",
        "# processed.count()\n",
        "# processed.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWg__nH0kZcq"
      },
      "source": [
        "# train, test = processed.randomSplit(weights=[0.7, 0.3], seed=123)\n",
        "# print(train.count())\n",
        "# print(test.count())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Nv2rjWkZcr",
        "outputId": "f9ed132f-c263-4723-eda9-2673a5f4537f"
      },
      "source": [
        "from pyspark.ml import feature as spark_ft\n",
        "\n",
        "stopWords = spark_ft.StopWordsRemover.loadDefaultStopWords('english')\n",
        "sw_remover = spark_ft.StopWordsRemover(inputCol='ntokens', outputCol='clean_tokens', stopWords=stopWords)\n",
        "text2vec = spark_ft.Word2Vec(\n",
        "    vectorSize=50, minCount=5, seed=123, \n",
        "    inputCol='ntokens', outputCol='text_vec', \n",
        "    windowSize=5, maxSentenceLength=30\n",
        ")\n",
        "assembler = spark_ft.VectorAssembler(inputCols=['text_vec'], outputCol='features')\n",
        "feature_pipeline = Pipeline(stages=[sw_remover, text2vec,assembler])\n",
        "feature_model = feature_pipeline.fit(train)\n",
        "\n",
        "train_featurized = feature_model.transform(train).persist()\n",
        "train_featurized.count()\n",
        "train_featurized.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|label|             comment|             ntokens|        clean_tokens|            text_vec|            features|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|    0|\"\"\"Agreed. I thin...|[agr, i, think, w...|[agr, think, issu...|[-0.0277247686728...|[-0.0277247686728...|\n",
            "|    0|\"\"\"It's kind of h...|[it, kind, of, ha...|[kind, hard, turn...|[-0.0212900592346...|[-0.0212900592346...|\n",
            "|    0|\"\"\"Mom\n",
            "Holy shitb...|[mom, holi, shitb...|[mom, holi, shitb...|[-0.0079348648898...|[-0.0079348648898...|\n",
            "|    0|\"\"\"People\"\"\n",
            "Umm, ...|[peopl, umm, he, ...|[peopl, umm, cant...|[-0.0139320314240...|[-0.0139320314240...|\n",
            "|    0|\"\"\"Play it cool; ...|[plai, it, cool, ...|[plai, cool, plai...|[-0.0255794662419...|[-0.0255794662419...|\n",
            "|    0|\"\"\"Said it last y...|[said, it, last, ...|[said, last, year...|[-0.0173314982658...|[-0.0173314982658...|\n",
            "|    0|\"\"\"The Witch\"\" is...|[the, witch, i, c...|[witch, complex, ...|[-0.0192479221150...|[-0.0192479221150...|\n",
            "|    0|\"\"\"The way I see ...|[the, wai, i, see...|[wai, see, liter,...|[-0.0350088400048...|[-0.0350088400048...|\n",
            "|    0|\"\"\"Tread lightly ...|[tread, lightli, ...|[tread, lightli, ...|[0.0,0.0,0.0,0.0,...|          (50,[],[])|\n",
            "|    0|\"\"\"You are like t...|[you, ar, like, t...|[ar, like, end, p...|[-0.0371367322950...|[-0.0371367322950...|\n",
            "|    0|\"@Senator_Assange...|[senatorassang, i...|[senatorassang, o...|[-0.0164033064075...|[-0.0164033064075...|\n",
            "|    0|\"A quick google s...|[a, quick, googl,...|[quick, googl, se...|[-0.0339884459901...|[-0.0339884459901...|\n",
            "|    0|\"Added flair per ...|[ad, flair, per, ...|[ad, flair, per, ...|[-0.0404106721398...|[-0.0404106721398...|\n",
            "|    0|\"Amazon is coming...|[amazon, i, come,...|[amazon, come, au...|[-0.0171267130951...|[-0.0171267130951...|\n",
            "|    0|\"And yet most of ...|[and, yet, most, ...|[yet, stoner, deg...|[-0.0448145184532...|[-0.0448145184532...|\n",
            "|    0|\"Another giveaway...|[anoth, giveawai,...|[anoth, giveawai,...|[-0.0164836971089...|[-0.0164836971089...|\n",
            "|    0|\"As a person who ...|[a, a, person, wh...|[person, doesnt, ...|[-0.0283221572539...|[-0.0283221572539...|\n",
            "|    0|\"BREAKING: Trump ...|[break, trump, ou...|[break, trump, ou...|[-0.0236269444146...|[-0.0236269444146...|\n",
            "|    0|\"Bug/Feature? Ver...|[bugfeatur, veri,...|[bugfeatur, veri,...|[-0.0208248905723...|[-0.0208248905723...|\n",
            "|    0|\"Charlie Kirk: \"\"...|[charli, kirk, if...|[charli, kirk, wa...|[-0.0207450918510...|[-0.0207450918510...|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntrUDG9nkZcr"
      },
      "source": [
        "from pyspark.ml import classification as spark_cls\n",
        "\n",
        "\n",
        "mlpc = spark_cls.MultilayerPerceptronClassifier(\n",
        "    maxIter=100, seed=123, layers=[50, 25, 10,2]\n",
        ")\n",
        "\n",
        "model = mlpc.fit(train_featurized)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkA_T6A6kZcs",
        "outputId": "61b4fe87-579b-4f16-882c-d969fa5a662a"
      },
      "source": [
        "test_featurized = feature_model.transform(test)\n",
        "preds = model.transform(test_featurized)\n",
        "preds.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|             comment|             ntokens|        clean_tokens|            text_vec|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|    0|\"\"\"Did Hillary Cl...|[did, hillari, cl...|[hillari, clinton...|[-0.0360369030890...|[-0.0360369030890...|[0.25204980283576...|[0.87505328308586...|       0.0|\n",
            "|    0|\"\"\"Gingrich\n",
            "And C...|[gingrich, and, c...|[gingrich, christ...|[-0.0311310966753...|[-0.0311310966753...|[0.32648835421839...|[0.89253965071566...|       0.0|\n",
            "|    0|\"\"\"Hey you wanna ...|[hei, you, wanna,...|[hei, wanna, get,...|[0.00124455507223...|[0.00124455507223...|[0.62729998326438...|[0.94636325127557...|       0.0|\n",
            "|    0|\"\"\"QR Code\"\"\n",
            "\"For...|[qr, code, for, s...|[qr, code, reason...|[-0.0122818929465...|[-0.0122818929465...|[0.57101459869294...|[0.93371451087623...|       0.0|\n",
            "|    0|\"\"\"The Germans bo...|[the, german, bom...|[german, bomb, pe...|[-0.0122401308959...|[-0.0122401308959...|[0.56877603921061...|[0.93282196231037...|       0.0|\n",
            "|    0|\"*Danny reaches f...|[danni, reach, fo...|[danni, reach, wa...|[-0.0193659959262...|[-0.0193659959262...|[0.59281746670600...|[0.93666470082488...|       0.0|\n",
            "|    0|\"*Guilt roles ove...|[guilt, role, ove...|[guilt, role, mel...|[-0.0355794915929...|[-0.0355794915929...|[0.45559149105341...|[0.91467858386092...|       0.0|\n",
            "|    0|\"90% of the time ...|[of, the, time, i...|[time, kid, try, ...|[-0.0239972680100...|[-0.0239972680100...|[0.42207897960437...|[0.91029594016381...|       0.0|\n",
            "|    0|\"Anyone else sort...|[anyon, els, sort...|[anyon, els, sort...|[-0.0231671842595...|[-0.0231671842595...|[0.32954211853838...|[0.89396941135890...|       0.0|\n",
            "|    0|\"BU only follows ...|[bu, onli, follow...|[bu, onli, follow...|[3.97051572157391...|[3.97051572157391...|[0.49467114690905...|[0.92498810803483...|       0.0|\n",
            "|    0|\"Can we have a \"\"...|[can, we, have, a...|[sorri, context, ...|[-0.0212013423588...|[-0.0212013423588...|[0.71358320703215...|[0.94964986857748...|       0.0|\n",
            "|    0|\"David Sirota on ...|[david, sirota, o...|[david, sirota, t...|[-0.0250456251184...|[-0.0250456251184...|[0.38704123260411...|[0.90281498527905...|       0.0|\n",
            "|    0|\"Electrical Engin...|[electr, engin, w...|[electr, engin, e...|[-0.0113814292520...|[-0.0113814292520...|[0.73581847483179...|[0.95242979175971...|       0.0|\n",
            "|    0|\"From what I've g...|[from, what, iv, ...|[iv, gather, ar, ...|[-0.0274833720759...|[-0.0274833720759...|[0.27014242583642...|[0.87909366884743...|       0.0|\n",
            "|    0|\"Has Persona 5 ma...|[ha, persona, mad...|[ha, persona, mad...|[-0.0274513977891...|[-0.0274513977891...|[0.42056395616309...|[0.91025001207230...|       0.0|\n",
            "|    0|\"Hey man, no need...|[hei, man, no, ne...|[hei, man, ne, ge...|[-0.0081108768084...|[-0.0081108768084...|[0.56726196534245...|[0.93666604434993...|       0.0|\n",
            "|    0|\"I dunno, doesnt ...|[i, dunno, doesnt...|[dunno, doesnt, m...|[-0.0304911700043...|[-0.0304911700043...|[0.53591908510106...|[0.92750156693699...|       0.0|\n",
            "|    0|\"I just worry (a ...|[i, just, worri, ...|[worri, littl, bi...|[-0.0365771862061...|[-0.0365771862061...|[0.17822888582758...|[0.85698370536939...|       0.0|\n",
            "|    0|\"I like how there...|[i, like, how, th...|[like, ye, decis,...|[-0.0257407204808...|[-0.0257407204808...|[0.24743258485460...|[0.87426985610316...|       0.0|\n",
            "|    0|\"I like the one w...|[i, like, the, on...|[like, ani, wai, ...|[-0.0418067051494...|[-0.0418067051494...|[0.31573413706585...|[0.88901130025950...|       0.0|\n",
            "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXPj8MICkZct"
      },
      "source": [
        "pred_df = preds.select('comment', 'label', 'prediction').toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx96IuFxkZct",
        "outputId": "99a46a94-543c-4244-ddaa-66d0634a5559"
      },
      "source": [
        "pred_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\"\"Did Hillary Clinton break the law?\"\" Chaffe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"\"\"Gingrich\\nAnd Christie will be in charge of...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"\"\"Hey you wanna get highhh\"\"\"\\nOh man, oh man...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\"\"QR Code\"\"\\n\"For some reason my brain was se...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"\"\"The Germans bombed Pearl Harbor\"\" Not sure ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  label  prediction\n",
              "0  \"\"\"Did Hillary Clinton break the law?\"\" Chaffe...      0         0.0\n",
              "1  \"\"\"Gingrich\\nAnd Christie will be in charge of...      0         0.0\n",
              "2  \"\"\"Hey you wanna get highhh\"\"\"\\nOh man, oh man...      0         0.0\n",
              "3  \"\"\"QR Code\"\"\\n\"For some reason my brain was se...      0         0.0\n",
              "4  \"\"\"The Germans bombed Pearl Harbor\"\" Not sure ...      0         0.0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk037-pJkZcu",
        "outputId": "af8afff6-d8d3-409b-f1d8-dda5771314c9"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics as skmetrics\n",
        "pd.DataFrame(\n",
        "    data=skmetrics.confusion_matrix(pred_df['label'], pred_df['prediction']),\n",
        "    columns=['pred ' + l for l in ['0','1']],\n",
        "    index=['true ' + l for l in ['0','1']]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred 0</th>\n",
              "      <th>pred 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true 0</th>\n",
              "      <td>537</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true 1</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pred 0  pred 1\n",
              "true 0     537       0\n",
              "true 1      62       0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn4SPCRdkZcu",
        "outputId": "bd243881-30c7-4fb6-a162-ae16bd000352"
      },
      "source": [
        "print(skmetrics.classification_report(pred_df['label'], pred_df['prediction'], \n",
        "                                      target_names=['0','1']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       537\n",
            "           1       0.00      0.00      0.00        62\n",
            "\n",
            "    accuracy                           0.90       599\n",
            "   macro avg       0.45      0.50      0.47       599\n",
            "weighted avg       0.80      0.90      0.85       599\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vkocaman/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-QM4l-wkZcu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}