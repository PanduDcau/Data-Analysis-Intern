{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5- How to use Spark NLP and Spark ML Pipelines.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z7qzgHN57Da"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IAGcd8757D3"
      },
      "source": [
        "# Spark NLP and Spark ML Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EPeAfbf57EN"
      },
      "source": [
        "## Simple Topic Modeling\n",
        "\n",
        "`Spark-NLP`\n",
        "* DocumentAssembler\n",
        "* SentenceDetector\n",
        "* Tokenizer\n",
        "* Normalizer\n",
        "* POS tagger\n",
        "* Chunker\n",
        "* Finisher\n",
        "\n",
        "`Spark ML`\n",
        "* Hashing\n",
        "* TF-IDF\n",
        "* LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICF9yp6sMuDq",
        "outputId": "fcd56a74-58a3-4c1a-a3d9-c50556b0f990"
      },
      "source": [
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 69 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 21.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 47.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEuzEtYE57Eg"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.clustering import LDA, LDAModel\n",
        "\n",
        "#Spark NLP\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import RegexRule\n",
        "from sparknlp.base import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVWI81h257FH"
      },
      "source": [
        "### Let's create a Spark Session for our app"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aMxhxT057FM",
        "outputId": "fbe5077e-41d3-4457-b0c7-a8a74ae8b571"
      },
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.3.4\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljYdLGFg57Fn"
      },
      "source": [
        "Let's download some scientific sample from PubMed dataset:\n",
        "```\n",
        "wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THoie2TP57Fq",
        "outputId": "9c6e6a3b-3ed8-4806-c455-2eed15510307"
      },
      "source": [
        "! wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 08:14:47--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.104.110\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.104.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10484510 (10.0M) [text/csv]\n",
            "Saving to: ‘/tmp/pubmed-sample.csv’\n",
            "\n",
            "pubmed-sample.csv   100%[===================>]  10.00M  28.5MB/s    in 0.4s    \n",
            "\n",
            "2021-12-02 08:14:48 (28.5 MB/s) - ‘/tmp/pubmed-sample.csv’ saved [10484510/10484510]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emTfVUoT57F1"
      },
      "source": [
        "pubMedDF = spark.read\\\n",
        "                .option(\"header\", \"true\")\\\n",
        "                .csv(\"/tmp/pubmed-sample.csv\")\\\n",
        "                .filter(\"AB IS NOT null\")\\\n",
        "                .withColumn(\"text\", col(\"AB\"))\\\n",
        "                .drop(\"TI\", \"AB\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJLM8EJg57F-",
        "outputId": "672d00bb-5959-456e-d5df-d02f8dbe7460"
      },
      "source": [
        "pubMedDF.printSchema()\n",
        "pubMedDF.show()\n",
        "print('rows', pubMedDF.count())\n",
        "pubMedDF = pubMedDF.limit(200) #minimize dataset if you are not running on a cluster"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            "\n",
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|The human KCNJ9 (...|\n",
            "|BACKGROUND: At pr...|\n",
            "|OBJECTIVE: To inv...|\n",
            "|Combined EEG/fMRI...|\n",
            "|Kohlschutter synd...|\n",
            "|Statistical analy...|\n",
            "|The synthetic DOX...|\n",
            "|Our objective was...|\n",
            "|We conducted a ph...|\n",
            "|\"Monomeric sarcos...|\n",
            "|We presented the ...|\n",
            "|The literature de...|\n",
            "|A novel approach ...|\n",
            "|An HPLC-ESI-MS-MS...|\n",
            "|The localizing an...|\n",
            "|OBJECTIVE: To eva...|\n",
            "|For the construct...|\n",
            "|We report the res...|\n",
            "|Intraparenchymal ...|\n",
            "|It is known that ...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "rows 7537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqdu2hFt57GL"
      },
      "source": [
        "### Let's create Spark-NLP Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF4bSQGg57GN",
        "outputId": "4e2a46ae-e080-4d8f-c8bc-5aae8e5149f2"
      },
      "source": [
        "# Spark NLP Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "posTagger = PerceptronModel.pretrained() \\\n",
        "  .setInputCols([\"sentence\", \"token\"])\n",
        "\n",
        "chunker = Chunker() \\\n",
        "    .setInputCols([\"sentence\", \"pos\"]) \\\n",
        "    .setOutputCol(\"chunk\") \\\n",
        "    .setRegexParsers([\"<NNP>+\", \"<DT>?<JJ>*<NN>\"])\n",
        "\n",
        "finisher = Finisher() \\\n",
        "  .setInputCols([\"chunk\"]) \\\n",
        "  .setIncludeMetadata(False)\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector, \n",
        "    tokenizer,\n",
        "    posTagger,\n",
        "    chunker,\n",
        "    finisher\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQpoBmBQ57GZ"
      },
      "source": [
        "nlpPipelineDF = nlpPipeline.fit(pubMedDF).transform(pubMedDF)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3cTHcvM57Gh"
      },
      "source": [
        "### Let's create Spark ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J86d68dw57Gi"
      },
      "source": [
        "# SPark ML Pipeline\n",
        "\n",
        "cv = CountVectorizer(inputCol=\"finished_chunk\", outputCol=\"features\", vocabSize=1000, minDF=10.0, minTF=10.0)\n",
        "idf = IDF(inputCol=\"features\", outputCol=\"idf\")\n",
        "lda = LDA(k=10, maxIter=5)\n",
        "### Let's create Spark-NLP Pipeline\n",
        "mlPipeline = Pipeline(stages=[\n",
        "    cv,\n",
        "    idf,\n",
        "    lda\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gsgIMYb57Gp"
      },
      "source": [
        "### We are going to train Spark ML Pipeline by using Spark-NLP Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02kj9BFc57Gr"
      },
      "source": [
        "# Let's create Spark-NLP Pipeline\n",
        "mlModel = mlPipeline.fit(nlpPipelineDF)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uePteSjt57Gw"
      },
      "source": [
        "mlPipelineDF = mlModel.transform(nlpPipelineDF)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1aJa9wq57G5",
        "outputId": "08f1fb3e-da21-4b4e-fa54-23b147470094"
      },
      "source": [
        "mlPipelineDF.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+----------+--------------------+\n",
            "|                text|      finished_chunk|  features|       idf|   topicDistribution|\n",
            "+--------------------+--------------------+----------+----------+--------------------+\n",
            "|The human KCNJ9 (...|[KCNJ9, Kir, GIRK...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|BACKGROUND: At pr...|[BACKGROUND, the ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|OBJECTIVE: To inv...|[OBJECTIVE, =9796...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|Combined EEG/fMRI...|[Combined EEG/fMR...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|Kohlschutter synd...|[Kohlschutter, sy...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|Statistical analy...|[Statistical, ana...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|The synthetic DOX...|[DOX-LNA, conjuga...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|Our objective was...|[objective, blood...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|We conducted a ph...|[II, a phase, stu...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|\"Monomeric sarcos...|[Monomeric, MSOX,...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|We presented the ...|[Exorista, Mythim...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|The literature de...|[The literature, ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|A novel approach ...|[A novel, approac...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|An HPLC-ESI-MS-MS...|[HPLC-ESI-MS-MS, ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|The localizing an...|[The localizing, ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|OBJECTIVE: To eva...|[OBJECTIVE, June,...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|For the construct...|[the construction...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|We report the res...|[PNP, GSTO, Yaqui...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|Intraparenchymal ...|[Intraparenchymal...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "|It is known that ...|[Klinefelter's, s...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
            "+--------------------+--------------------+----------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suE9r6hs57HB"
      },
      "source": [
        "ldaModel = mlModel.stages[2]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXM4vDp57HH",
        "outputId": "974df478-ffdb-4ea3-9430-51f67083276d"
      },
      "source": [
        "ll = ldaModel.logLikelihood(mlPipelineDF)\n",
        "lp = ldaModel.logPerplexity(mlPipelineDF)\n",
        "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
        "print(\"The upper bound on perplexity: \" + str(lp))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lower bound on the log likelihood of the entire corpus: -507.62578437116224\n",
            "The upper bound on perplexity: 22.070686277007052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxnifLA257HO",
        "outputId": "87ab0ead-d67d-44ea-d4ec-4f7fd9c86054"
      },
      "source": [
        "# Describe topics.\n",
        "print(\"The topics described by their top-weighted terms:\")\n",
        "ldaModel.describeTopics(3).show(truncate=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The topics described by their top-weighted terms:\n",
            "+-----+------------+------------------------------------------------------------------+\n",
            "|topic|termIndices |termWeights                                                       |\n",
            "+-----+------------+------------------------------------------------------------------+\n",
            "|0    |[33, 16, 14]|[0.03018628309769907, 0.029681217516439682, 0.02869041483345357]  |\n",
            "|1    |[8, 12, 30] |[0.03091504468994952, 0.030564905055513247, 0.030347406718960728] |\n",
            "|2    |[38, 23, 34]|[0.030800605263050097, 0.0303272771337697, 0.030183291985159597]  |\n",
            "|3    |[35, 10, 1] |[0.03224629748995109, 0.031950817237563725, 0.030392057367293862] |\n",
            "|4    |[23, 3, 37] |[0.03324215054134379, 0.029263134932537502, 0.02901417457626244]  |\n",
            "|5    |[13, 30, 25]|[0.03229819762533601, 0.03228638681256154, 0.0304560373241258]    |\n",
            "|6    |[13, 37, 5] |[0.030097751872073652, 0.029355989145604066, 0.029005240587263746]|\n",
            "|7    |[5, 24, 4]  |[0.0318190860429291, 0.03168316394538527, 0.029143542945572448]   |\n",
            "|8    |[10, 24, 3] |[0.030287433352533578, 0.030183222724734376, 0.030082854755264843]|\n",
            "|9    |[35, 32, 25]|[0.029786846898155025, 0.029320518901691163, 0.029187640180553056]|\n",
            "+-----+------------+------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63TxUsJw57HS"
      },
      "source": [
        "### Let's look at out topics\n",
        "NOTE: More cleaning, filtering, playing around with `CountVectorizer`, and more iterations in `LDA` will result in better Topic Modelling results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVzJ8Vcv57HU",
        "outputId": "80d989da-2bea-4a5e-9604-f7f33ae99bdc"
      },
      "source": [
        "# Output topics. Each is a distribution over words (matching word count vectors)\n",
        "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
        "      + \" words):\")\n",
        "\n",
        "topics = ldaModel.describeTopics(20)\n",
        "topics_rdd = topics.rdd\n",
        "\n",
        "vocab = mlModel.stages[0].vocabulary\n",
        "\n",
        "topics_words = topics_rdd\\\n",
        "       .map(lambda row: row['termIndices'])\\\n",
        "       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
        "       .collect()\n",
        "\n",
        "for idx, topic in enumerate(topics_words):\n",
        "    print(\"topic: \", idx)\n",
        "    print(\"----------\")\n",
        "    for word in topic:\n",
        "        print(word)\n",
        "    print(\"----------\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned topics (as distributions over vocab of 39 words):\n",
            "topic:  0\n",
            "----------\n",
            "level\n",
            "activity\n",
            "BACKGROUND\n",
            "addition\n",
            "contrast\n",
            "CONCLUSIONS\n",
            "response\n",
            "function\n",
            "study\n",
            "rate\n",
            "therapy\n",
            "analysis\n",
            "protein\n",
            "OBJECTIVE\n",
            "P\n",
            "PURPOSE\n",
            "CONCLUSION\n",
            "method\n",
            "cell\n",
            "vivo\n",
            "----------\n",
            "topic:  1\n",
            "----------\n",
            "analysis\n",
            "DNA\n",
            "response\n",
            "expression\n",
            "age\n",
            "function\n",
            "P\n",
            "BACKGROUND\n",
            "therapy\n",
            "family\n",
            "cancer\n",
            "<\n",
            "contrast\n",
            "addition\n",
            "protein\n",
            "risk\n",
            "OBJECTIVE\n",
            "METHODS\n",
            "CONCLUSION\n",
            "),\n",
            "----------\n",
            "topic:  2\n",
            "----------\n",
            "factor\n",
            "disease\n",
            "contrast\n",
            "cancer\n",
            "therapy\n",
            "CONCLUSION\n",
            "protein\n",
            "this study\n",
            "<\n",
            "METHODS\n",
            "gene\n",
            "level\n",
            "study\n",
            "activity\n",
            "vitro\n",
            "age\n",
            "P\n",
            "treatment\n",
            "response\n",
            "method\n",
            "----------\n",
            "topic:  3\n",
            "----------\n",
            "family\n",
            "CONCLUSIONS\n",
            "),\n",
            "contrast\n",
            "expression\n",
            "function\n",
            "response\n",
            "vitro\n",
            "this study\n",
            "serum\n",
            "gene\n",
            "cell\n",
            "DNA\n",
            "OBJECTIVE\n",
            "CONCLUSION\n",
            "activity\n",
            ").\n",
            "BACKGROUND\n",
            "study\n",
            "treatment\n",
            "----------\n",
            "topic:  4\n",
            "----------\n",
            "disease\n",
            "METHODS\n",
            "vivo\n",
            "group\n",
            "<\n",
            "cancer\n",
            "study\n",
            "function\n",
            "DNA\n",
            "risk\n",
            "analysis\n",
            "family\n",
            "CONCLUSIONS\n",
            "factor\n",
            "serum\n",
            "vitro\n",
            "response\n",
            "CONCLUSION\n",
            "expression\n",
            ").\n",
            "----------\n",
            "topic:  5\n",
            "----------\n",
            "rate\n",
            "response\n",
            "method\n",
            ").\n",
            "P\n",
            "level\n",
            "age\n",
            "activity\n",
            "protein\n",
            "OBJECTIVE\n",
            "contrast\n",
            "PURPOSE\n",
            "vivo\n",
            "),\n",
            "function\n",
            "METHODS\n",
            "disease\n",
            "cell\n",
            "study\n",
            "CONCLUSIONS\n",
            "----------\n",
            "topic:  6\n",
            "----------\n",
            "rate\n",
            "vivo\n",
            "protein\n",
            "serum\n",
            "time\n",
            "risk\n",
            "method\n",
            "treatment\n",
            "disease\n",
            "BACKGROUND\n",
            "analysis\n",
            ").\n",
            "cancer\n",
            "study\n",
            "function\n",
            "cell\n",
            "CONCLUSIONS\n",
            "activity\n",
            "PURPOSE\n",
            "this study\n",
            "----------\n",
            "topic:  7\n",
            "----------\n",
            "protein\n",
            "time\n",
            "cancer\n",
            "study\n",
            "CONCLUSIONS\n",
            "vitro\n",
            "analysis\n",
            "vivo\n",
            "P\n",
            "<\n",
            "),\n",
            "BACKGROUND\n",
            "DNA\n",
            "addition\n",
            "treatment\n",
            "contrast\n",
            "gene\n",
            "CONCLUSION\n",
            "therapy\n",
            "method\n",
            "----------\n",
            "topic:  8\n",
            "----------\n",
            "CONCLUSIONS\n",
            "time\n",
            "METHODS\n",
            "serum\n",
            "activity\n",
            "age\n",
            "CONCLUSION\n",
            "disease\n",
            "PURPOSE\n",
            "vitro\n",
            "P\n",
            "analysis\n",
            "cancer\n",
            "gene\n",
            "<\n",
            "rate\n",
            "),\n",
            ").\n",
            "DNA\n",
            "cell\n",
            "----------\n",
            "topic:  9\n",
            "----------\n",
            "family\n",
            "risk\n",
            "method\n",
            "contrast\n",
            "addition\n",
            "vitro\n",
            "study\n",
            "group\n",
            "cell\n",
            "PURPOSE\n",
            "METHODS\n",
            "<\n",
            "therapy\n",
            "factor\n",
            "age\n",
            "disease\n",
            "this study\n",
            "serum\n",
            ").\n",
            "expression\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sInJRlxfMooO"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}