{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA_Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaKUNmLKIAjr"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/ABSA_Inference.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkeqSGefIJW-"
      },
      "source": [
        "# **Aspect Based Sentiment Analysis in Spark NLP**\n",
        "\n",
        "#### Model Details: https://nlp.johnsnowlabs.com/2020/12/29/ner_aspect_based_sentiment_en.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhA_CmHaIRQz"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbO7pJJqIV_T"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgtx3Ji1JK2W"
      },
      "source": [
        "Install Dependencies and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWoA7SChHu41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13394ef-50a1-411e-c7ef-38da3c918e11"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-27 08:47:12--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-27 08:47:12--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-27 08:47:13--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-27 08:47:13 (67.4 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 65 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 43.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4GalFKIasv"
      },
      "source": [
        "Import and start the Spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "gdmZSvJNIeQP",
        "outputId": "57cb3919-2305-43fe-ab0a-75cc89354f11"
      },
      "source": [
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "# manually start session\n",
        "'''\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('Spark NLP Licensed') \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.driver.memory', '16G') \\\n",
        "    .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n",
        "    .config('spark.kryoserializer.buffer.max', '2000M') \\\n",
        "    .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()).getOrCreate()\n",
        "'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nspark = SparkSession.builder     .appName('Spark NLP Licensed')     .master('local[*]')     .config('spark.driver.memory', '16G')     .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')     .config('spark.kryoserializer.buffer.max', '2000M')     .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()).getOrCreate()\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBW8SeRnIf1-"
      },
      "source": [
        "##2. Build Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FzKvkdBHu44",
        "outputId": "0648705b-9839-4dcc-b82d-f4f4f249ca73"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['sentence']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"glove_6B_300\", \"xx\")\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "    \n",
        "ner_model = NerDLModel.pretrained(\"ner_aspect_based_sentiment\")\\\n",
        "    .setInputCols([\"document\", \"token\", \"embeddings\"])\\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    ner_model,\n",
        "    ner_converter])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "light_pipeline = LightPipeline(pipeline_model)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_6B_300 download started this may take some time.\n",
            "Approximate size to download 426.2 MB\n",
            "[OK!]\n",
            "ner_aspect_based_sentiment download started this may take some time.\n",
            "Approximate size to download 21.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzf1KWDzJhk2"
      },
      "source": [
        "## 3. Create example inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOGmXRQ0Jw6X"
      },
      "source": [
        "# Enter examples as strings in this array\n",
        "input_list = [\n",
        "    \"\"\"From the beginning, we were met by friendly staff members, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.\"\"\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W10hpftJ0D5"
      },
      "source": [
        "## 4. Run the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9BMNDC8MSeS"
      },
      "source": [
        "Full Pipeline (Expects a spark Data Frame)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAdIbN4rJzXh"
      },
      "source": [
        "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
        "result = pipeline_model.transform(df)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHYdK2aKMXaC"
      },
      "source": [
        "Light Pipeline (Expects a list of string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrEfJogLMaZP"
      },
      "source": [
        "lresult = light_pipeline.fullAnnotate(input_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnPhWxstJ53j"
      },
      "source": [
        "## 5. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1tfkrE1MmfN"
      },
      "source": [
        "Full Pipeline Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "xXjYtpVuURln",
        "outputId": "a4f6b37f-0c23-4b42-9b31-4e7f1e834367"
      },
      "source": [
        "# Using display lib\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(result.collect()[0], 'ner_chunk', 'document')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">From the beginning, we were met by friendly </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #252F3D\"><span class=\"spark-nlp-display-entity-name\">staff members </span><span class=\"spark-nlp-display-entity-type\">POS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rv-Li9DJ6S7",
        "outputId": "4b1789f7-afd5-4838-dfd2-7081e3ae98bb"
      },
      "source": [
        "# Process manually\n",
        "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
        "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
        "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
        "result.select(exploded.alias(\"cols\")) \\\n",
        "    .select(select_expression_0, select_expression_1).show(truncate=False)\n",
        "result = result.toPandas()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------+\n",
            "|chunk        |ner_label|\n",
            "+-------------+---------+\n",
            "|staff members|POS      |\n",
            "+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd1qdsbdMoUF"
      },
      "source": [
        "Light Pipeline Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "MAkhpH_TVMhK",
        "outputId": "3092b63a-594b-40a7-b48f-839944fcd3aa"
      },
      "source": [
        "# Using display lib\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(lresult[0], 'ner_chunk', 'document')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">From the beginning, we were met by friendly </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #367A8F\"><span class=\"spark-nlp-display-entity-name\">staff members </span><span class=\"spark-nlp-display-entity-type\">POS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJGdtmLSMrao",
        "outputId": "098ca71c-4ca6-4bce-b7f9-f89251a25ec6"
      },
      "source": [
        "# Process manually\n",
        "for example in lresult:\n",
        "  for res in example['ner_chunk']:\n",
        "    print ('Token/Phrase:', res.result, 'Sentiment: ', res.metadata['entity'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token/Phrase: staff members Sentiment:  POS\n"
          ]
        }
      ]
    }
  ]
}